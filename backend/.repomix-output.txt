This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-09T10:11:49.351Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
$MYVIMDIR/
alembic/
  versions/
    543703d68501_defining_relationship_between_users_.py
    958ccda321d9_add_unique_id_to_basemodel.py
    96f48dd56dbf_changing_relationship_between_user_and_.py
    cb2cfa1f74a0_changing_relationship_between_tasks_and_.py
  env.py
  README
  script.py.mako
local-docs/
v1/
  actions/
    __init__.py
    index.py
    log.py
    report.py
    task.py
    user.py
  database_setup/
    create_tables.sql
    setup_mysql_dev.sql
    setup_mysql_test.sql
  models/
    engine/
      storage.py
    __init__.py
    .gitignore
    basemodel.py
    dailylog.py
    task.py
    user.py
  __init__.py
  app.py
  requirements.txt
  wsgi.py
v2/
  activity/
    functions.py
    index.py
    validation.py
  alembic/
    versions/
      10ec9562f6b3_changing_the_basemodel_class.py
      543703d68501_defining_relationship_between_users_.py
      6e5ab13242e1_updating_the_profile_table.py
      958ccda321d9_add_unique_id_to_basemodel.py
      96f48dd56dbf_changing_relationship_between_user_and_.py
      cb2cfa1f74a0_changing_relationship_between_tasks_and_.py
      f91c39ca4f32_renaming_the_task_table_to_activity.py
    env.py
    README
    script.py.mako
  auth/
    functions.py
    index.py
    validation.py
  engine/
    storage.py
  models/
    __init__.py
    Activity.py
    base.py
    Basemodel.py
    Profile.py
    Report.py
    User.py
  report/
    __init__.py
    functions.py
    index.py
    validation.py
  utils/
    middleware.py
  __init__.py
  .gitignore
  alembic.ini
  app.py
  index.py
  pyproject.toml
.cursorrules
.gitignore
.python-version
alembic.ini
package.json
tc_dev_db_backup.sql
timecraft.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="alembic/versions/543703d68501_defining_relationship_between_users_.py">
"""Defining relationship between users, tasks and logs so that tasks can be deleted when user is deleted and so on
Revision ID: 543703d68501
Revises: cb2cfa1f74a0
Create Date: 2024-11-05 20:26:58.495474
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '543703d68501'
down_revision: Union[str, None] = 'cb2cfa1f74a0'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
</file>

<file path="alembic/versions/958ccda321d9_add_unique_id_to_basemodel.py">
"""Add unique_id to basemodel
Revision ID: 958ccda321d9
Revises: 
Create Date: 2024-11-05 14:08:48.977451
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '958ccda321d9'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('daily_log', sa.Column('unique_id', sa.String(length=8), nullable=True))
    op.create_unique_constraint(None, 'daily_log', ['unique_id'])
    op.add_column('tasks', sa.Column('unique_id', sa.String(length=8), nullable=True))
    op.create_unique_constraint(None, 'tasks', ['unique_id'])
    op.add_column('users', sa.Column('unique_id', sa.String(length=8), nullable=True))
    op.create_unique_constraint(None, 'users', ['unique_id'])
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'users', type_='unique')
    op.drop_column('users', 'unique_id')
    op.drop_constraint(None, 'tasks', type_='unique')
    op.drop_column('tasks', 'unique_id')
    op.drop_constraint(None, 'daily_log', type_='unique')
    op.drop_column('daily_log', 'unique_id')
    # ### end Alembic commands ###
</file>

<file path="alembic/versions/96f48dd56dbf_changing_relationship_between_user_and_.py">
"""Changing relationship between user and task to be by unique_id instead of id
Revision ID: 96f48dd56dbf
Revises: 958ccda321d9
Create Date: 2024-11-05 15:14:38.954660
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '96f48dd56dbf'
down_revision: Union[str, None] = '958ccda321d9'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('tasks_user_id_fkey', 'tasks', type_='foreignkey')
    op.create_foreign_key(None, 'tasks', 'users', ['user_id'], ['unique_id'])
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'tasks', type_='foreignkey')
    op.create_foreign_key('tasks_user_id_fkey', 'tasks', 'users', ['user_id'], ['id'])
    # ### end Alembic commands ###
</file>

<file path="alembic/versions/cb2cfa1f74a0_changing_relationship_between_tasks_and_.py">
"""Changing relationship between tasks and logs to be by unique_id instead of id
Revision ID: cb2cfa1f74a0
Revises: 96f48dd56dbf
Create Date: 2024-11-05 15:18:07.164549
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = 'cb2cfa1f74a0'
down_revision: Union[str, None] = '96f48dd56dbf'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('daily_log_task_id_fkey', 'daily_log', type_='foreignkey')
    op.create_foreign_key(None, 'daily_log', 'tasks', ['task_id'], ['unique_id'])
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'daily_log', type_='foreignkey')
    op.create_foreign_key('daily_log_task_id_fkey', 'daily_log', 'tasks', ['task_id'], ['id'])
    # ### end Alembic commands ###
</file>

<file path="alembic/env.py">
from logging.config import fileConfig
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from models.basemodel import BaseModel, Base
from dotenv import load_dotenv
from alembic import context
import os
load_dotenv()  # Load environment variables from .env file
# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config
DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL is None:
    raise ValueError("No DATABASE_URL found in environment variables")
# Set the SQLAlchemy URL manually
config.set_main_option("sqlalchemy.url", DATABASE_URL)
# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)
# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
target_metadata = Base.metadata
# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.
def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.
    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.
    Calls to context.execute() here emit the given string to the
    script output.
    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()
def run_migrations_online() -> None:
    """Run migrations in 'online' mode.
    In this scenario we need to create an Engine
    and associate a connection with the context.
    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )
        with context.begin_transaction():
            context.run_migrations()
if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
</file>

<file path="alembic/README">
Generic single-database configuration.
</file>

<file path="alembic/script.py.mako">
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
</file>

<file path="v1/actions/__init__.py">
#!/usr/bin/python3
""" Blueprint for API """
from flask import Blueprint
# Create the blueprint
app_actions = Blueprint('actions', __name__, url_prefix='')
# Import all the views(actions)
from api.v1.actions.index import *
from api.v1.actions.user import *
from api.v1.actions.task import *
from api.v1.actions.log import *
from api.v1.actions.report import *
</file>

<file path="v1/actions/index.py">
#!/usr/bin/python
""" Index """
from api.v1.actions import app_actions
from flask import jsonify, request, abort
# Returns a status indicator for the API
@app_actions.route('/status', methods=['GET'], strict_slashes=False)
def status():
    """ Status of API """
    return jsonify({"status": "OK"})
</file>

<file path="v1/actions/log.py">
#!/usr/bin/python
""" Handles creation of a new User """
from models import storage
from models.user import User
from models.task import Task
from models.dailylog import DailyLog
from api.v1.actions import app_actions
from flasgger.utils import swag_from
from flask import jsonify, request, abort
from datetime import datetime
@app_actions.route('/new_log', methods=['POST'], strict_slashes=False)
def new_log():
    """ Creates a new log """
    # Empty Dictionary
    log_dict = dict()
    # Save all the form data in variables
    task_id = request.form.get('taskId')
    task_name = request.form.get('taskName')
    user_id = request.form.get('userId');
    # print("User ID:", user_id)
    # print("Task name:", task_name, "Task ID:", task_id)
    if not task_id:
        task_id = storage.get_task_id_by_task_name(task_name)
        # print("Task Id by task name:", task_id)
    log_dict['task_id'] = task_id
    task = storage.get_task(task_id)
    if not task:
        return jsonify({"message": "Couldn't find a task with that name/ID"}), 404
    # print("Task:", task)
    user = storage.get_user(user_id)
    tot = float(request.form.get('timeOnTask'))
    twt = float(request.form.get('timeWasted'))
    # Calculate the month, day and year of the day the log is being made
    month = datetime.today().strftime("%B")
    day = datetime.today().strftime("%-d")
    year = datetime.today().strftime("%Y")
    # Store all the above data in the dictionary
    log_dict['month'] = month
    log_dict['day'] = day
    log_dict['year'] = year
    log_dict['date'] = f"{month}.{day}.{year}"
    log_dict['day_of_week'] = datetime.today().weekday()
    log_dict['time_on_task'] = tot
    log_dict['time_wasted'] = twt
    # Update metrics that need to be changed on User and Task objects
    task.total_time_on_task += tot
    task.save()
    user.total_productive_time += tot
    user.total_wasted_time += twt
    user.save()
    # Creates a new log object and saves it
    try:
        new_log = DailyLog(**log_dict)
        storage.new(new_log)
        storage.save()
        return jsonify({'message': 'Log created successfully'})
    except:
        storage.rollback()
        return jsonify({'message': 'Unknown error occured. Please try again'}), 500
</file>

<file path="v1/actions/report.py">
#!/usr/bin/python
""" Handles reports for users """
from models import storage
from models.user import User
from models.dailylog import DailyLog
from api.v1.actions import app_actions
from flasgger.utils import swag_from
from datetime import datetime, timedelta
from flask import jsonify, request, abort
@app_actions.route('/report/daily', methods=['POST', 'GET'],
                   strict_slashes=False)
def daily_report():
    """ Provides a daily report for the current user """
    # Gets User ID from the form
    user_id = request.form.get('userId')
    print('User Id:', user_id)
    ''' Get the date and format the string into something compatible with
        the Log object's "date" attribute '''
    date = request.form.get('date')
    print('Date:', date)
    # date = date.replace('-', '.')
    # date = date.replace(':', '.')
    # date = date.replace(',', '.')
    # date = date.replace(' ', '.')
    ''' Handles the case of the user getting a report for "today" and not a
        specific date '''
    if date == "today":
        date = datetime.today().strftime("%B.%-d.%Y")
    else:
        date = datetime.strptime(date, "%Y-%m-%d").strftime("%B.%-d.%Y")
    print("Formatted date:", date)
    # Get all logs that are for the given date
    logs = storage.get_logs_of_the_day(date)
    tasks = []
    ttot_day = 0
    twt_day = 0
    # If there are no logs for that date
    if logs:
        # Go through all the logs and add up the work time and wasted time metrics
        for log in logs:
            task = storage.get_task(log.task_id)
            print("Task:", task)
            if task.user_id == user_id:
                tasks.append({
                    'name': task.task_name,
                    'ttot': log.time_on_task,
                })
                ttot_day += log.time_on_task
                twt_day += log.time_wasted
    else:
        return jsonify({ 'message': "There are no logs for this day. Please pick another date"}), 404
    # Store result in the dictionary
    task_names = set(task['name'] for task in tasks)
    task_tally_dict = {name: 0 for name in task_names}
    for task in tasks:
        for name in task_names:
            if task['name'] == name:
                task_tally_dict[name] += task['ttot']
    unique_tasks = [{'name': name, 'ttot': tally } for name, tally in task_tally_dict.items()]
    daily_report = {
        'ttot_day': ttot_day,
        'twt_day': twt_day,
        'date': date.replace(".", " "),
        'weekday': datetime.strptime(date, "%B.%d.%Y").strftime("%A"),
        'tasks': unique_tasks,
    } 
    return jsonify({'report': daily_report}), 200
@app_actions.route('/report/weekly', methods=['POST', 'GET'],
                   strict_slashes=False)
def weekly_report():
    """ Provides a weekly report for the current user """
    user_id = request.form.get('userId')
    user = storage.get_user(user_id)
    ''' Gets the "week" to get a report for.
        week is one of 3 things. "this_week", "last_week", or "custom"
    '''
    week = request.form.get('week')
    # Takes in an actual datetime object
    def this_week(date):
        """ Gets a weekly report from Monday to Sunday based on a
            given date. """
        # Gets the difference of the given date and the beginning of the week
        weekday_offset = date.weekday()
        # Calculate the date for Monday of that week
        start_date = date - timedelta(days=weekday_offset)
        # Calculate the date for Sunday of that week
        end_date = start_date + timedelta(days=6)
        # Total productive and wasted time for the week
        tasks = []
        ttot_week = 0
        twt_week = 0
        # Get logs from Monday to Sunday of that week
        day = start_date
        while day < end_date:
            log_id = day.strftime("%B.%-d.%Y")
            logs = storage.get_logs_of_the_day(log_id)
            for log in logs:
                task = storage.get_task(log.task_id)
                if task.user_id == user_id:
                    tasks.append({
                        'name': task.task_name,
                        'ttot': log.time_on_task,
                    })
                    ttot_week += log.time_on_task
                    twt_week += log.time_wasted
            day += timedelta(days=1)
        task_names = set(task['name'] for task in tasks)
        task_tally_dict = {name: 0 for name in task_names}
        for task in tasks:
            for name in task_names:
                if task['name'] == name:
                    task_tally_dict[name] += task['ttot']
        unique_tasks = [{'name': name, 'ttot': tally } for name, tally in task_tally_dict.items()]
        # Initialize a dictionary and store the report to be returned
        weekly_report = {
            'ttot_week': ttot_week,
            'twt_week': twt_week,
            'start_date': start_date.strftime("%a, %d %b, %Y"),
            'end_date': end_date.strftime("%a, %d %b, %Y"),
            'tasks': unique_tasks,
        }
        return jsonify({'report': weekly_report}), 200
    # Gets today's date
    today = datetime.today()
    if week == "this_week":
        year = datetime.today().strftime("%Y")
        return this_week(today)
    elif week == "last_week":
        year = datetime.today().strftime("%Y")
        # Provides a date for a day exactly a week from today
        return this_week(today - timedelta(days=7))
    else:
        ''' Gets the custom date and formats it to match a Log object's
            date attribute
        '''
        custom_date = request.form.get('date')
        print(custom_date)
        custom_date =  datetime.strptime(custom_date, "%Y-%m-%d")
        # custom_date = custom_date.replace(' ', '.')
        # custom_date = custom_date.replace('-', '.')
        # custom_date = custom_date.replace(',', '.')
        # custom_date = custom_date.replace(':', '.')
        # Converts the string to an actual datetime object
        year = custom_date.strftime("%Y")
        return this_week(custom_date)
@app_actions.route('/report/monthly', methods=['POST', 'GET'],
                   strict_slashes=False)
def monthly_report():
    """ Provides a monthly report for the current user """
    user_id = request.form.get('userId')
    user = storage.get_user(user_id)
    month = request.form.get('month')
    year = int(datetime.today().strftime("%Y"))
    # total time on task month
    ttot_month = 0
    # total wasted time month
    twt_month = 0
    tasks = []
    # Get all logs in storage and filter by month
    logs = storage.get_logs_of_the_day()
    logs_of_the_month = []
    for log in logs:
        if log.year == year:
            if log.month == month:
                logs_of_the_month.append(log)
    # If there are no logs for the given month
    if not logs_of_the_month:
        return jsonify({'message': "Looks like there are no logs for tha month. Please try another one"}), 404
    # Get the hourly mesurments for the report on the month
    for log in logs_of_the_month:
        task = storage.get_task(log.task_id)
        if task.user_id== user_id:
            tasks.append({
                'name': task.task_name,
                'ttot': log.time_on_task,
            })
            ttot_month += log.time_on_task
            twt_month += log.time_wasted
    task_names = set(task['name'] for task in tasks)
    task_tally_dict = {name: 0 for name in task_names}
    for task in tasks:
        for name in task_names:
            if task['name'] == name:
                task_tally_dict[name] += task['ttot']
    unique_tasks = [{'name': name, 'ttot': tally } for name, tally in task_tally_dict.items()]
    # Store the report in a dictionary
    monthly_report = {
            'ttot_month': ttot_month,
            'twt_month': twt_month,
            'month': month,
            'year': year,
            'tasks': unique_tasks,
        }
    return jsonify({ 'report': monthly_report })
@app_actions.route('/report/productive', methods=['POST', 'GET'],
                   strict_slashes=False)
def total_productive_time():
    """ Gets the total productive time for a User """
    user_id = request.form.get('userId')
    user = storage.get_user(user_id)
    if not user:
        return jsonify({'message': 'No user with that id. Please try again'}), 200
    # Dictionary to store the total productive time
    tpt = {'tpt': 0}
    # Get's a User's total productive time and store it in the dictionary
    tpt['tpt'] = user.total_productive_time
    return jsonify({'report': tpt})
@app_actions.route('/report/wasted', methods=['POST', 'GET'],
                   strict_slashes=False)
def total_wasted_time():
    """ Gets the total wasted time for a User """
    user_id = request.form.get('userId')
    user = storage.get_user(user_id)
    if not user:
        return jsonify({'message': 'No user with that id. Please try again'}), 200
    # Get a User's total wasted time and store it in a dictionary
    twt = {
            'twt': user.total_wasted_time
        }
    return jsonify({'report': twt})
</file>

<file path="v1/actions/task.py">
#!/usr/bin/python
""" Handles all commands related to Tasks """
from models.__init__ import storage
from models.task import Task
from models.user import User
from api.v1.actions import app_actions
from flask import abort, jsonify, make_response, request
from flasgger.utils import swag_from
from sqlalchemy.exc import IntegrityError
@app_actions.route('/tasks/create', methods=['POST'], strict_slashes=False)
def new_task():
    """ Creates a new task """
    # Gets the user ID from the form
    user_id = request.form.get('userId')
    if not user_id:
        return jsonify({"error": "User ID not provided"}), 400
    # print("User ID", user_id)
    # Empty Dictionray
    task_dict = dict()
    # Get the User from storage
    user = storage.get_user(user_id)
    if user is None:
        return jsonify({"message": "Couldn't find user with that ID"}), 404
    # Assign form data about Task to the empty dictionary
    task_dict['user_id'] = user_id
    task_dict['task_name'] = request.form.get('taskName')
    task_dict['daily_goal'] = float(request.form.get('dailyGoal'))
    task_dict['weekly_goal'] = task_dict['daily_goal'] *\
        user.number_of_work_days
    # Create a new Task object and save it
    try:
        new_task = Task(**task_dict)
        storage.new(new_task)
        storage.save()
        return jsonify({'message': 'Task created successfully', 'data': {'task_id': new_task.unique_id}}), 201
    except IntegrityError as e:
        storage.rollback()
        return jsonify({'message': 'Task name has to be unique. Please try again'}), 400
    except Exception as e:
        storage.rollback()
        return jsonify({'message': 'Unkown error occured. Please try again'}), 500
@app_actions.route('/tasks', methods=['POST'], strict_slashes=False)
def all_tasks():
    """Gets all tasks associated with the user"""
    user_id = request.form.get('userId')
    # print("User ID:", user_id)
    if not user_id:
        return jsonify({"message": "User ID not provided"}), 400
    try: 
        tasks = storage.get_task_by_user_id(user_id)
        task_names = [task.task_name for task in tasks]
        user_tasks = [{
            'name': task.task_name,
            'id': task.unique_id,
            'ttot': task.total_time_on_task
        } for task in tasks]
        return jsonify({'tasks': user_tasks, 'task_names': task_names })
    except Exception as e:
        return ({"message": "Error fetching tasks."}), 500
@app_actions.route('/tasks/total', methods=['POST', 'GET'],
                   strict_slashes=False)
def total_time_on_task():
    """ Gets the total time spent on task """
    task_id = request.form.get('taskId')
    task_name = request.form.get('taskName')
    if not task_id:
        task_id = storage.get_task_id_by_task_name(task_name)
        print("Task Id by task name:", task_id)
    # Gets a specific task from storage using the Task ID
    task = storage.get_task(task_id)
    if task is None:
        return jsonify({'message': "Couldn't find a task with that ID. Please try agian."}), 400
    # print('Ttot:', task.total_time_on_task)
    return jsonify({'report':{
        'ttot': task.total_time_on_task,
        'taskName': task.task_name
        }
    })
@app_actions.route("/tasks/update", methods=['POST'], strict_slashes=False)
def update_task():
    ''' Update a task's name '''
    task_id = request.form.get('taskId')
    new_name = request.form.get('newName')
    print("Task Id:", task_id)
    if not task_id:
        return ({ 'message': 'Task ID is required. Please try again'}), 400
    task = storage.get_task(task_id)
    if task is None:
        return jsonify({'message': "Couldn't find a task with that ID. Please try again. "}), 404
    if task.task_name == new_name:
        return jsonify({'message': "No change detected"}), 400
    try:
        storage.change_task_name(new_name, task_id)
        return jsonify({ 'message': 'Task updated successfully' }), 200
    except IntegrityError as e:
        # print(e)
        storage.rollback()
        return jsonify({ 'message': "A task with this name already exists. Please change it and try again" }), 400
    except Exception as e:
        # print(e)
        storage.rollback()
        return jsonify({ 'message': 'Unknown error occured. Please try again' }), 500
@app_actions.route("/tasks/delete", methods=['DELETE'], strict_slashes=False)
def delete_task():
    """ Deletes a task. """
    task_id = request.form.get("taskId")
    if not task_id:
        return jsonify({'message': 'Task Id is required'}), 400
    task = storage.get_task(task_id)
    if not task:
        return jsonify({'message': "Couldn't find a task with that ID"}), 404
    try:
        storage.delete(task)
        return jsonify({'message': 'Task deleted successfully!'}), 200
    except Exception as e:
        # print(e)
        storage.rollback()
        return jsonify({'message': 'Unkown error occured. Please try again'}), 500
</file>

<file path="v1/actions/user.py">
#!/usr/bin/python
""" Handles creation of a new User """
from models import storage
from models.user import User
from v1.actions import app_actions
from flasgger.utils import swag_from
from flask import jsonify, request, abort
from jose import jwt, JWTError
from passlib.context import CryptContext
from datetime import timedelta, datetime
from sqlalchemy.exc import IntegrityError
import json
SECRET_KEY = '027aaad3-d8d2-4067-8689-af1a461c4c0e'
AlGORITHM = 'HS256'
bcrypt_context = CryptContext(schemes=['bcrypt'], deprecated='auto')
@app_actions.route('/user/create', methods=['POST'], strict_slashes=False)
def new_user():
    """ Creates a new user """
    # Empty Dictionary
    user_dict = dict()
    # Get all necessary info about User from the form
    name = request.form.get('username')
    # weekly work hours goal
    wwg = request.form.get('weekly_hours')
    work_days = request.form.get('work_days')
    # Save the data ina dictionary
    user_dict['username'] = name
    user_dict['weekly_work_hours_goal'] = float(wwg)
    user_dict['number_of_work_days'] = int(work_days)
    # Create an object based on the data and save it
    try:
        new_user = User(**user_dict)
        storage.new(new_user)
        storage.save()
        return jsonify({'message': 'User created successfully!', 'data': {'user_id': new_user.unique_id} }), 201
    except IntegrityError as e:
        storage.rollback()
        return jsonify({'message': 'The username already exists. Please use a different one'}), 400
    except Exception as e:
        storage.rollback()
        return jsonify({'message': 'Unkown error occured. Please try again'}), 500
@app_actions.route('/signup', methods=['POST'], strict_slashes=False)
def signup():
    """ Signs up a new User """
    # Get all necessary info about User from the form
    user_model = dict(
        username=request.form.get('username'),
        email=request.form.get('email'),
        weekly_work_hours_goal=request.form.get('weekly_hours'),
        number_of_work_days=request.form.get('work_days'),
        password=bcrypt_context.hash(request.form.get('password')),
    )
    try:
        new_user = User(**user_model)
        new_user.save()
        return jsonify({ 'message': 'User signed up successfully!'}), 201
    except IntegrityError:
        storage.rollback()
        return jsonify({'message': 'The username/email already exists. Please use a different one'}), 400
    except Exception as e:
        print(e)
        storage.rollback()
        return jsonify({'message': 'Unkown error occured. Please try again'}), 500
@app_actions.route('/login', methods=['POST'], strict_slashes=False)
def login():
    """ Login user """
    # Get all necessary info about User from the form
    login_model = dict(
        email=request.form.get('email'),
        password=request.form.get('password')
    )
    user = storage.get_user_by_email(login_model['email'])
    if not user:
         return jsonify({ 'message': "Couldn't find a user with that email"}), 404
    if not bcrypt_context.verify(login_model['password'], user.password):
        return jsonify({ 'message': "Incorrect email or password" }), 405
    returning_user = {
        'email': user.email,
        'username': user.username,
        'id': user.unique_id,
        'tpt': user.total_productive_time,
        'twt': user.total_wasted_time,
    }
    token = create_access_token(user.email, user.id ,timedelta(minutes=20))
    return jsonify({ 'message': 'Login successful!', 'data': {'token': token, 'user': returning_user} }), 200
def create_access_token(email, id, expires_delta):
    expire = datetime.now() + expires_delta
    encode = { 'email': email, 'id': id, 'exp': expire.timestamp() }
    return jwt.encode(encode, SECRET_KEY, algorithm=AlGORITHM)
@app_actions.route('/get_session_user', methods=['GET'], strict_slashes=False)
def get_session_user():
    """ Gets a user for the session """
    return jsonify({"user_id": storage.user_id})
@app_actions.route('/switch_user', methods=['POST'], strict_slashes=False)
def switch_user():
    """ Changes the user for the session """
    user_id = request.json.get("userId")
    user = storage.get_user(user_id)
    if user is None:
        return jsonify({})
    storage.user_id = user_id
    storage.save()
    return jsonify({'name': user.name})
@app_actions.route('/user/update', methods=['POST'], strict_slashes=False)
def update_user() :
    """ Changes the user data """
    user_id = request.form.get('userId')
    username = request.form.get('username')
    if not username:
        return ({'message': 'username is required'}), 400
    user = storage.get_user(user_id)
    if user is None:
        return jsonify({'message': "Couldn't find a user with that ID. Please try again." }), 404
    if user.username == username:
        return jsonify({'message': "No change detected"}), 400
    try:
        storage.change_username(username, user_id)
        return jsonify({ 'message': 'User updated successfully!'}), 200
    except IntegrityError as e:
        storage.rollback()
        return jsonify({'message': 'The username is taken. Please change it and try again'} ), 400
    except Exception as e:
        storage.rollback()
        # print(e)
        return jsonify({'message': 'Unkown error occured. Please try again'}), 500
@app_actions.route('/user/delete', methods=['DELETE'], strict_slashes=False)
def delete_user():
    ''' Delete the user '''
    user_id = request.form.get('userId')
    print("User Id:", user_id)
    if not user_id:
        return jsonify({'message': "User Id is required"}), 400
    user = storage.get_user(user_id)
    if not user:
        return jsonify({ 'message': "Couldn't find that user. Please try again"}), 404
    try:
        storage.delete(user)
        storage.save()
        return jsonify({'message': 'User deleted successfully!'}), 200
    except Exception as e:
        storage.rollback()
        print(e)
        return jsonify({'message': 'Unkown error occured. Please try again'}), 500
</file>

<file path="v1/database_setup/create_tables.sql">
-- Creates the necessay tables for TimeCraft to operate
-- Creates a table for users
CREATE TABLE IF NOT EXISTS users (
    name VARCHAR(128) NOT NULL,
    email VARCHAR(128),
    password VARCHAR(255),
    weekly_work_hours_goal FLOAT NOT NULL,
    number_of_work_days INT NOT NULL,
    id VARCHAR(60) PRIMARY KEY,
    created_at DATETIME NOT NULL,
    updated_at DATETIME NOT NULL,
    total_wasted_time FLOAT NOT NULL DEFAULT 0,
    total_productive_time FLOAT NOT NULL DEFAULT 0
);
-- Creates a table for tasks
CREATE TABLE IF NOT EXISTS tasks (
    id VARCHAR(60) PRIMARY KEY,
    created_at DATETIME NOT NULL,
    updated_at DATETIME NOT NULL,
    task_name VARCHAR(128) NOT NULL,
    total_time_on_task FLOAT,
    daily_goal FLOAT NOT NULL,
    weekly_goal FLOAT NOT NULL,
    user_id VARCHAR(60) NOT NULL,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
);
-- creates a table for logs
CREATE TABLE daily_log(
    id VARCHAR(60) PRIMARY KEY,
    created_at DATETIME NOT NULL,
    updated_at DATETIME NOT NULL,
    month VARCHAR(60) NOT NULL,
    day INT NOT NULL,
    year INT NOT NULL,
    task_id VARCHAR(128) NOT NULL,
    time_on_task FLOAT NOT NULL,
    time_wasted FLOAT NOT NULL,
    day_of_week VARCHAR(55) NOT NULL,
    date VARCHAR(255) NOT NULL,
    FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE
);
</file>

<file path="v1/database_setup/setup_mysql_dev.sql">
-- Prepares a MySQL dev server for TimeCraft
-- Creates the database if it doesn't exist
CREATE DATABASE IF NOT EXISTS tc_dev_db;
-- Create user if it doesn't exist
CREATE USER IF NOT EXISTS 'tc_dev'@'localhost' IDENTIFIED BY 'passwd';
-- Grants all privileges to the created user on the dev db
GRANT ALL PRIVILEGES ON tc_dev_db.* TO 'tc_dev'@'localhost';
</file>

<file path="v1/database_setup/setup_mysql_test.sql">
-- Prepares a MySQL test server for the project
-- Creates the test db if it doesn't exist
CREATE DATABASE IF NOT EXISTS tc_test_db;
-- Creates the user if it doesn't exist
CREATE USER IF NOT EXISTS 'tc_test'@'localhost' IDENTIFIED BY 'tc_test_pwd_4796';
-- Grants all privileges on the test db to the created user
GRANT ALL PRIVILEGES ON tc_test_db.* TO 'tc_test'@'localhost';
-- Grants select privilege to the created user on the performace_schema db
GRANT SELECT ON performace_schema.* TO 'tc_test'@'localhost';
</file>

<file path="v1/models/engine/storage.py">
#!/usr/bin/env python3
''' Handles the database storage for TimeCraft '''
import os
import sys
import sqlalchemy
from sqlalchemy import (create_engine, update)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
from models.basemodel import Base
from models.user import User
from models.task import Task
from models.dailylog import DailyLog
from contextlib import contextmanager
from dotenv import load_dotenv
load_dotenv()  # Load environment variables from .env file
DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL is None:
   raise ValueError("No DATABASE_URL found in environment variables")
class Storage:
    ''' This class defines handles the storage of our data '''
    __engine = None
    __session = None
    user_id = None
    def __init__(self):
        ''' Insantization '''
        # We are using the dev database
        # self.__engine = create_engine(DATABASE_URL)
        #         # We are using the dev database
        self.__engine = create_engine(DATABASE_URL)
    def all_tasks(self, usr):
        ''' Query the current databse session all tasks belonging to the user
        '''
        task_list = []
        # Converts the string into the corresponding object
        if type(usr) is str:
            usr = eval(usr)
        usr_id = usr.id
        # Gets all Tasks in storage
        tasks = self.__session.query(Task).filter(Task.id == usr_id)
        # Filter the tasks assigned to our user
        # for task in tasks:
        #     if task.user_id == usr_id:
        #         task_list.append(task)
        return tasks
    def total_time_on_task(self, usr, task):
        ''' Gets the total time spent across all tasks OR
            total time spent on one task if task is specified '''
        tasks = self.all_tasks(usr)
        total_time_on_task = 0
        # Goes through all the tasks related to the user
        for tsk in tasks:
            if tsk.id == task.id:
                return task.total_time_on_task
        return total_time_on_task
    def get_user(self, user_id=None):
        """ Get a user(Users) from the list of users """
        # Get all User objects in storage
        users = self.__session.query(User)
        if user_id:
            for user in users:
                if user.unique_id == user_id:
                    return user
            return None
        # If no User Id given, return all User objects(for internal usage)
        return users
    def get_user_by_email(self, email):
        ''' Get user byy email address '''
        return self.__session.query(User).filter(User.email == email).first()
    def get_task(self, task_id=None):
        """ Get a task(or all tasks) from the list of tasks """
        # Get all Task objects in storage
        tasks = self.__session.query(Task)
        if task_id:
            for task in tasks:
                if task.unique_id == task_id:
                    return task
            return None
        # If noto Task ID is given, return all Task objects(for internal use)
        return tasks
    def get_task_by_user_id(self, user_id):
        ''' Get a task by user Id '''
        return self.__session.query(Task).filter(Task.user_id == user_id)
    def get_task_id_by_task_name(self, task_name):
        ''' Get task's Id by task name'''
        return self.__session.query(Task).filter(Task.task_name == task_name).first().unique_id
    def get_logs_of_the_day(self, log_date=None):
        """ Gets a log(or all logs) from the list of logs """
        # Get all Log objects in storarge
        logs = self.__session.query(DailyLog)
        logs_of_the_day = []
        if log_date:
            for log in logs:
                # Get all logs for a given date
                if log.date == log_date:
                    logs_of_the_day.append(log)
            return logs_of_the_day
        # If no log date given, return all DailyLog objects(for internal use)
        return logs
    def new(self, obj):
        ''' Adds a new object to the session '''
        self.__session.add(obj)
    def set_user_id(self, user_id):
        ''' Sets a user id for the session '''
        self.user_id = user_id
    def change_username(self, username, user_id):
        ''' Change username of a user '''
        update_query = (
            update(User)
            .where(User.unique_id == user_id)
            .values(username=username)
        )
        with self.__session as session:
            session.execute(update_query)
            session.commit()
    def change_task_name(self, new_name, task_id):
        ''' Change task name of a task '''
        update_query = (
            update(Task)
            .where(Task.unique_id == task_id)
            .values(task_name = new_name)
        )
        with self.__session as session:
            session.execute(update_query)
            session.commit()
    def save(self):
        ''' Saves all changes made in the session '''
        self.__session.commit()
    def delete(self, obj):
        ''' Deletes an object from the database '''
        if obj:
            # with self.__session as session:
            self.__session.delete(obj)
    def reload(self):
        ''' Creates all tables in the database and the current db session '''
        Base.metadata.create_all(self.__engine)
        session_factory = sessionmaker(bind=self.__engine,
                                       expire_on_commit=False)
        Session = scoped_session(session_factory)
        # Starts the session
        self.__session = Session()
    def rollback(self):
        ''' Roll back the current session in case of error '''
        self.__session.rollback()
    def close(self):
        ''' Closes the current session '''
        self.__session.close()
</file>

<file path="v1/models/__init__.py">
#!/usr/bin/python3
''' Initalization model creates a storage object '''
from models.engine.storage import Storage
from models.user import User
from models.task import Task
from models.dailylog import DailyLog
from os import getenv
storage = Storage()
storage.reload()
</file>

<file path="v1/models/.gitignore">
# Enviroment variables
.env
__pycache__
</file>

<file path="v1/models/basemodel.py">
#!/usr/bin/python3
"""This module defines a base class for all models in our hbnb clone"""
import uuid
import string
import secrets
import models
from datetime import datetime
from sqlalchemy.orm import declarative_base
from sqlalchemy import String, Column, Integer, DateTime
Base = declarative_base()
class BaseModel:
    """A base class for all timecraft modeles"""
    id = Column(String(60), primary_key=True)
    created_at = Column(DateTime, nullable=False, default=datetime.now())
    updated_at = Column(DateTime, nullable=False, default=datetime.now())
    unique_id = Column(String(8), unique=True)
    def __generate_id__(self, length=8):
        """ Creates an 8 digit secure ID """
        chars = string.ascii_lowercase + string.digits
        return ''.join(secrets.choice(chars) for _ in range(length))
    def __init__(self, **kwargs):
        """Instantiates a new model"""
        if not kwargs.get('id'):
            self.id = str(uuid.uuid4())
        if not kwargs.get('created_at'):
            self.created_at = datetime.now()
        if not kwargs.get('updated_at'):
            self.updated_at = datetime.now()
        self.unique_id = self.__generate_id__()
        self.__dict__.update(kwargs)
    def __str__(self):
        ''' Returns a string representation of an instance '''
        filtered_dict = {k: v for k, v in self.__dict__.items() if v}
        return f'[{type(self).__name__}] ({self.id}) {filtered_dict}'
    def save(self):
        """ Updates updated_at with current time when instance is changed.
            Also saves an instance to the database. """
        self.updated_at = datetime.now()
        models.storage.new(self)
        models.storage.save()
    def to_dict(self):
        """ Converts an instance to a dictionary """
        dictionary = {}
        for key, value in self.__dict__.items():
            if value is not None:
                dictionary[key] = value
        # Makes sure the private attribute "class" is the class name
        dictionary["__class__"] = self.__class__.__name__
        return dictionary
    def delete(self):
        """ Deletes the current instance from storage """
        models.storage.delete(self)
</file>

<file path="v1/models/dailylog.py">
#!/usr/bin/env python3
from models.basemodel import BaseModel, Base
from sqlalchemy import Column, String, Float, Integer, ForeignKey
from sqlalchemy.orm import relationship
from datetime import datetime
class DailyLog(BaseModel, Base):
    ''' This is the class representation of the Object DailyLog '''
    __tablename__ = "daily_log"
    month = Column(String(60), nullable=False)
    day = Column(Integer, nullable=False)
    year = Column(Integer, nullable=False)
    task_id = Column(String(128), ForeignKey("tasks.unique_id"), nullable=False)
    time_on_task = Column(Float, nullable=False, default=0)
    time_wasted = Column(Float, nullable=False, default=0)
    day_of_week = Column(String(55), nullable=False)
    date = Column(String(60), nullable=True)
    task = relationship("Task", back_populates="logs")
</file>

<file path="v1/models/task.py">
#!/usr/bin/env python3
''' This module contains the class definition of Task '''
from models.basemodel import BaseModel, Base
from sqlalchemy import Column, String, Float, ForeignKey
from sqlalchemy.orm import relationship
class Task(BaseModel, Base):
    ''' This is the class that will represent Task objects '''
    __tablename__ = "tasks"
    task_name = Column(String(128), nullable=False, unique=True)
    total_time_on_task = Column(Float, default=0)
    daily_goal = Column(Float, nullable=False)
    weekly_goal = Column(Float, nullable=False)
    user_id = Column(String(60), ForeignKey("users.unique_id"), nullable=False)
    user = relationship("User", back_populates="tasks")
    logs = relationship("DailyLog", back_populates="task", cascade="all, delete-orphan")
</file>

<file path="v1/models/user.py">
#!/usr/bin/env python3
''' This module contains the class User '''
from models.basemodel import BaseModel, Base
from sqlalchemy import Column, String, Float, Integer
from sqlalchemy.orm import relationship
class User(BaseModel, Base):
    ''' This class is the represantation for the User object '''
    __tablename__ = "users"
    username = Column(String(128), nullable=False, unique=True)
    email = Column(String(128), nullable=True, unique=True)
    password = Column(String(255), nullable=True)
    weekly_work_hours_goal = Column(Float, nullable=False)
    number_of_work_days = Column(Integer, nullable=False)
    total_productive_time = Column(Float, nullable=False, default=0)
    total_wasted_time = Column(Float, nullable=False, default=0)
    tasks = relationship("Task", back_populates="user", cascade="all, delete-orphan")
</file>

<file path="v1/__init__.py">

</file>

<file path="v1/app.py">
#!/usr/bin/python3
""" Flask App """
from models import storage
from os import environ
from flask import Flask, render_template, make_response, jsonify
from flask_cors import CORS
from flasgger import Swagger
from flasgger.utils import swag_from
from api.v1.actions import app_actions
# Initializinig app
app = Flask(__name__)
app.config['JSONIFY_PRETTYPRINT-REGULAR'] = True
# Registering a bluepring on app
app.register_blueprint(app_actions, url_prefix="/api")
# Setting up Cross-Origin-Resource_Sharing properly
CORS(app, resources={r"/api*": {"origins": "*"}})
# Closes the Database session when necessary
@app.teardown_appcontext
def close_db(error):
    """ Terminate database session """
    storage.close()
# Handles 404 errors
@app.errorhandler(404)
def not_found(error):
    """ 404 Error
    ---
    response:
      404:
        description: a resource was not found
    """
    return make_response(jsonify({'error': "NOT FOUND"}), 404)
# Documentaiton tool
app.config['SWAGGER'] = {
    'title': 'TimeCraft',
    'uiversion': 3
}
Swagger(app)
# Run the Flask app
if __name__ == "__main__":
    """ Main Function """
    host = environ.get('HBNB_API_HOST')
    port = environ.get('HBNB_API-PORT')
    if not host:
        host = '0.0.0.0'
    if not port:
        port = 5000
    app.run(host=host, port=port, threaded=True, debug=True)
</file>

<file path="v1/requirements.txt">
alembic==1.14.0
annotated-types==0.7.0
anyio==4.4.0
appdirs==1.4.4
asgiref==3.8.1
attrs==23.2.0
bcrypt==3.1.7
blinker==1.7.0
build==1.2.1
certifi==2024.6.2
cffi==1.16.0
charset-normalizer==3.3.2
click==8.1.7
coreapi==2.3.3
coreschema==0.0.4
crispy-bootstrap4==2024.1
cryptography==42.0.8
decorator==5.1.1
defusedxml==0.7.1
Deprecated==1.2.14
dj-database-url==0.5.0
dj-rest-auth==6.0.0
Django==5.0.3
django-allauth==0.61.1
django-anymail==10.3
django-cors-headers==4.4.0
django-crispy-forms==2.1
django-environ==0.11.2
djangorestframework==3.15.1
dnspython==2.6.1
ecdsa==0.19.0
email_validator==2.2.0
Fabric3==1.14.post1
fastapi==0.111.1
fastapi-cli==0.0.4
flasgger==0.9.7.1
Flask==3.0.0
Flask-Cors==4.0.0
greenlet==3.0.3
gunicorn==22.0.0
h11==0.14.0
httpcore==1.0.5
httptools==0.6.1
httpx==0.27.0
idna==3.7
invoke==2.2.0
isoweek==1.3.3
itsdangerous==2.1.2
itypes==1.2.0
Jinja2==3.1.3
jose==1.0.0
jsonschema==4.20.0
jsonschema-specifications==2023.12.1
Mako==1.3.6
markdown-it-py==3.0.0
MarkupSafe==2.1.3
mdurl==0.1.2
mistune==3.0.2
mysql-connector-python==8.3.0
mysqlclient==2.2.4
oauthlib==3.2.2
packaging==23.2
paramiko==2.12.0
passlib==1.7.4
pep8==1.7.1
pillow==10.3.0
psycopg2==2.9.9
pyasn1==0.6.0
pycodestyle==2.11.1
pycparser==2.22
pydantic==2.8.2
pydantic_core==2.20.1
Pygments==2.18.0
PyJWT==2.8.0
PyNaCl==1.3.0
pyparsing==3.1.2
pyproject_hooks==1.0.0
python-dotenv==1.0.1
python-jose==3.3.0
python-multipart==0.0.9
python3-openid==3.2.0
PyYAML==6.0.1
referencing==0.32.1
requests==2.32.3
requests-oauthlib==2.0.0
rich==13.7.1
rpds-py==0.17.1
rsa==4.9
shellingham==1.5.4
shortuuid==1.0.13
six==1.16.0
sniffio==1.3.1
SQLAlchemy==2.0.27
sqlparse==0.4.4
starlette==0.37.2
typer==0.12.3
typing_extensions==4.10.0
uritemplate==4.1.1
urllib3==2.2.1
uvicorn==0.30.1
uvloop==0.19.0
watchfiles==0.22.0
websockets==12.0
Werkzeug==3.0.1
whitenoise==6.7.0
wrapt==1.16.0
</file>

<file path="v1/wsgi.py">
from api.v1.app import app  # Import the Flask app instance
if __name__ == "__main__":
    app.run()  # Only needed if running the app directly for testing
</file>

<file path="v2/activity/functions.py">
from v2.models.Activity import Activity
from v2.models import storage
def get_activity_by_name(user_id: str, name: str) -> Activity:
    """Get an activity by name for a specific user"""
    return storage.session.query(Activity).filter(
        Activity.user_id == user_id,
        Activity.name == name,
        Activity.deleted == None
    ).first()
def get_all_activities(user_id: str) -> list[Activity]:
    """Get all activities for a specific user"""
    return storage.session.query(Activity).filter(
        Activity.user_id == user_id,
        Activity.deleted == None
    ).all()
def get_activity_by_id(activity_id: str) -> Activity:
    """Get an activity by ID"""
    return storage.session.query(Activity).filter(
        Activity.unique_id == activity_id,
        Activity.deleted == None
    ).first()
</file>

<file path="v2/activity/index.py">
"""Task routes"""
from datetime import datetime
from v2.activity.functions import get_activity_by_id
from v2.activity.validation import CreateActivityRequest, UpdateActivityRequest
from v2.activity.functions import get_activity_by_name, get_all_activities
from v2 import router
from flask import jsonify, request, abort
from v2.models.Activity import Activity
from v2.models import storage
from v2.utils.middleware import auth_middleware
from flasgger.utils import swag_from
from sqlalchemy.exc import IntegrityError
@router.route('/activity', methods=['POST'], strict_slashes=False)
@auth_middleware
def create_activity():
    """Create a new activity for the authenticated user"""
    try:
        data = request.get_json() if request.is_json else request.form
        validated_data = CreateActivityRequest.model_validate(data)
        # Check if user already has an activity with this name
        existing_activity = get_activity_by_name(request.user['id'], validated_data.name)
        if existing_activity:
            return jsonify({
                'message': 'You already have an activity with this name'
            }), 400
        # Create new task
        new_activity = Activity(
            name=validated_data.name,
            description=validated_data.description,
            daily_goal=validated_data.daily_goal,
            weekly_goal=validated_data.weekly_goal,
            user_id=request.user['id'],  # Link task to current user's profile
            total_time_on_task=0
        )
        try:
            new_activity.save()
        except Exception as e:
            storage.rollback()
            return jsonify({
                'message': str(e)
            }), 500
        # Convert task to dictionary for response
        activity_dict = {
            'id': new_activity.id,
            'unique_id': new_activity.unique_id,
            'name': new_activity.name,
            'description': new_activity.description,
            'daily_goal': new_activity.daily_goal,
            'weekly_goal': new_activity.weekly_goal,
            'total_time_on_task': new_activity.total_time_on_task,
            'created_at': new_activity.created_at.isoformat(),
            'updated_at': new_activity.updated_at.isoformat()
        }
        return jsonify({
            'message': 'Activity created successfully',
            'data': activity_dict
        }), 201
    except ValueError as e:
        return jsonify({
            'message': str(e)
        }), 400
    except Exception as e:
        return jsonify({
            'message': str(e)
        }), 500
@router.route('/activity', methods=['GET'], strict_slashes=False)
@auth_middleware
def get_activities():
    """Get all activities for the authenticated user"""
    try:
        # Query activities for the current user that aren't deleted
        activities = get_all_activities(request.user['id'])
        # Convert activities to list of dictionaries
        activities_list = []
        for activity in activities:
            activities_list.append({
                'id': activity.id,
                'unique_id': activity.unique_id,
                'name': activity.name,
                'description': activity.description,
                'daily_goal': activity.daily_goal,
                'weekly_goal': activity.weekly_goal,
                'total_time_on_task': activity.total_time_on_task,
                'created_at': activity.created_at.isoformat(),
                'updated_at': activity.updated_at.isoformat()
            })
        return jsonify({
            'message': 'Activities retrieved successfully',
            'data': activities_list
        }), 200
    except Exception as e:
        return jsonify({
            'message': str(e)
        }), 500
@router.route('/activity/<activity_id>', methods=['GET'], strict_slashes=False)
@auth_middleware
def get_activity(activity_id):
    """Get a specific activity by ID"""
    try:
        # Query the activity
        activity = get_activity_by_id(activity_id)
        if not activity:
            return jsonify({
                'message': 'Activity not found'
            }), 404
        # Convert activity to dictionary
        activity_dict = {
            'id': activity.id,
            'unique_id': activity.unique_id,
            'name': activity.name,
            'description': activity.description,
            'daily_goal': activity.daily_goal,
            'weekly_goal': activity.weekly_goal,
            'total_time_on_task': activity.total_time_on_task,
            'created_at': activity.created_at.isoformat(),
            'updated_at': activity.updated_at.isoformat()
        }
        return jsonify({
            'message': 'Activity retrieved successfully',
            'data': activity_dict
        }), 200
    except Exception as e:
        return jsonify({
            'message': str(e)
        }), 500
@router.route('/activity/<activity_id>', methods=['PATCH'], strict_slashes=False)
@auth_middleware
def update_activity(activity_id):
    """Update a specific activity"""
    try:
        # Get and validate request data
        data = request.get_json() if request.is_json else request.form
        update_data = UpdateActivityRequest.model_validate(data)
        # Query the activity
        updated_activity = get_activity_by_id(activity_id)
        if not updated_activity:
            abort(404, description="Activity not found")
        # Check if name is being updated and conflicts with existing activity
        if hasattr(update_data, 'name') and update_data.name != updated_activity.name:
            # Check if any other activity exists with this name for the user
            existing_activity = get_activity_by_name(updated_activity.user_id, update_data.name)
            if existing_activity:
                return jsonify({
                    'message': "You already have an activity with this name"
                }), 400
        # Update only provided fields
        if update_data.name:
            updated_activity.name = update_data.name
        if update_data.description:
            updated_activity.description = update_data.description
        if update_data.daily_goal:
            updated_activity.daily_goal = update_data.daily_goal
        if update_data.weekly_goal:
            updated_activity.weekly_goal = update_data.weekly_goal
        if update_data.total_time_on_task:
            updated_activity.total_time_on_task = update_data.total_time_on_task
        updated_activity.updated_at = datetime.now()
        try:
            updated_activity.save()
        except Exception as e:
            storage.rollback()
            return jsonify({
                'message': str(e)
            }), 500
        # Convert updated activity to dictionary
        activity_dict = {
            'id': updated_activity.id,
            'unique_id': updated_activity.unique_id,
            'name': updated_activity.name,
            'description': updated_activity.description,
            'daily_goal': updated_activity.daily_goal,
            'weekly_goal': updated_activity.weekly_goal,
            'total_time_on_task': updated_activity.total_time_on_task,
            'created_at': updated_activity.created_at.isoformat(),
            'updated_at': updated_activity.updated_at.isoformat()
        }
        return jsonify({
            'message': 'Activity updated successfully',
            'data': activity_dict
        }), 200
    except ValueError as e:
        return jsonify({
            'message': str(e)
        }), 400
    except Exception as e:
        return jsonify({
            'message': str(e)
        }), 500
@router.route('/activity/<activity_id>', methods=['DELETE'], strict_slashes=False)
@auth_middleware
def delete_activity(activity_id):
    """Soft delete a specific activity"""
    try:
        # Query the activity
        activity = get_activity_by_id(activity_id)
        if not activity:
            return jsonify({
                'message': "Activity not found"
            }), 404
        # Soft delete the activity
        activity.deleted = datetime.now()
        activity.save()
        return jsonify({
            'message': 'Activity deleted successfully'
        }), 200
    except Exception as e:
        return jsonify({
            'message': str(e)
        }), 500
</file>

<file path="v2/activity/validation.py">
"""Task validation schemas"""
from pydantic import BaseModel, Field, field_validator
from typing import Optional
class CreateActivityRequest(BaseModel):
    """Validation schema for activity creation"""
    name: str = Field(..., min_length=1, max_length=128)
    description: str = Field(..., min_length=1, max_length=1024)
    daily_goal: float = Field(..., gt=0)
    weekly_goal: float = Field(..., gt=0)
    @field_validator('weekly_goal')
    @classmethod
    def weekly_goal_must_be_greater_than_daily(cls, v: float, info) -> float:
        daily_goal = info.data.get('daily_goal')
        if daily_goal is not None and v < daily_goal * 7:
            raise ValueError('Weekly goal must be at least equal to daily goal times 7')
        return v
class UpdateActivityRequest(BaseModel):
    """Validation schema for activity updates"""
    name: str | None = Field(None, min_length=1, max_length=128)
    description: str | None = Field(None, min_length=1, max_length=1024)
    daily_goal: float | None = Field(None, gt=0)
    weekly_goal: float | None = Field(None, gt=0)
    total_time_on_task: float | None = Field(None)
    @field_validator('weekly_goal')
    @classmethod
    def weekly_goal_must_be_greater_than_daily(cls, v: float | None, info) -> float | None:
        if v is None:
            return v
        daily_goal = info.data.get('daily_goal')
        if daily_goal is not None and v < daily_goal:
            raise ValueError('Weekly goal must be at least equal to daily goal')
        return v
</file>

<file path="v2/alembic/versions/10ec9562f6b3_changing_the_basemodel_class.py">
"""Changing the Basemodel class
Revision ID: 10ec9562f6b3
Revises: 6e5ab13242e1
Create Date: 2025-02-24 14:56:13.959251
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '10ec9562f6b3'
down_revision: Union[str, None] = '6e5ab13242e1'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    pass
def downgrade() -> None:
    pass
</file>

<file path="v2/alembic/versions/543703d68501_defining_relationship_between_users_.py">
"""Defining relationship between users, tasks and logs so that tasks can be deleted when user is deleted and so on
Revision ID: 543703d68501
Revises: cb2cfa1f74a0
Create Date: 2024-11-05 20:26:58.495474
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '543703d68501'
down_revision: Union[str, None] = 'cb2cfa1f74a0'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
</file>

<file path="v2/alembic/versions/6e5ab13242e1_updating_the_profile_table.py">
"""Updating the profile table
Revision ID: 6e5ab13242e1
Revises: 543703d68501
Create Date: 2025-02-24 14:46:41.010644
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '6e5ab13242e1'
down_revision: Union[str, None] = '543703d68501'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    pass
def downgrade() -> None:
    pass
</file>

<file path="v2/alembic/versions/958ccda321d9_add_unique_id_to_basemodel.py">
"""Add unique_id to basemodel
Revision ID: 958ccda321d9
Revises: 
Create Date: 2024-11-05 14:08:48.977451
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '958ccda321d9'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('daily_log', sa.Column('unique_id', sa.String(length=8), nullable=True))
    op.create_unique_constraint(None, 'daily_log', ['unique_id'])
    op.add_column('tasks', sa.Column('unique_id', sa.String(length=8), nullable=True))
    op.create_unique_constraint(None, 'tasks', ['unique_id'])
    op.add_column('users', sa.Column('unique_id', sa.String(length=8), nullable=True))
    op.create_unique_constraint(None, 'users', ['unique_id'])
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'users', type_='unique')
    op.drop_column('users', 'unique_id')
    op.drop_constraint(None, 'tasks', type_='unique')
    op.drop_column('tasks', 'unique_id')
    op.drop_constraint(None, 'daily_log', type_='unique')
    op.drop_column('daily_log', 'unique_id')
    # ### end Alembic commands ###
</file>

<file path="v2/alembic/versions/96f48dd56dbf_changing_relationship_between_user_and_.py">
"""Changing relationship between user and task to be by unique_id instead of id
Revision ID: 96f48dd56dbf
Revises: 958ccda321d9
Create Date: 2024-11-05 15:14:38.954660
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = '96f48dd56dbf'
down_revision: Union[str, None] = '958ccda321d9'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('tasks_user_id_fkey', 'tasks', type_='foreignkey')
    op.create_foreign_key(None, 'tasks', 'users', ['user_id'], ['unique_id'])
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'tasks', type_='foreignkey')
    op.create_foreign_key('tasks_user_id_fkey', 'tasks', 'users', ['user_id'], ['id'])
    # ### end Alembic commands ###
</file>

<file path="v2/alembic/versions/cb2cfa1f74a0_changing_relationship_between_tasks_and_.py">
"""Changing relationship between tasks and logs to be by unique_id instead of id
Revision ID: cb2cfa1f74a0
Revises: 96f48dd56dbf
Create Date: 2024-11-05 15:18:07.164549
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = 'cb2cfa1f74a0'
down_revision: Union[str, None] = '96f48dd56dbf'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('daily_log_task_id_fkey', 'daily_log', type_='foreignkey')
    op.create_foreign_key(None, 'daily_log', 'tasks', ['task_id'], ['unique_id'])
    # ### end Alembic commands ###
def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'daily_log', type_='foreignkey')
    op.create_foreign_key('daily_log_task_id_fkey', 'daily_log', 'tasks', ['task_id'], ['id'])
    # ### end Alembic commands ###
</file>

<file path="v2/alembic/versions/f91c39ca4f32_renaming_the_task_table_to_activity.py">
"""Renaming the Task table to Activity
Revision ID: f91c39ca4f32
Revises: 10ec9562f6b3
Create Date: 2025-02-24 23:15:31.524837
"""
from typing import Sequence, Union
from alembic import op
import sqlalchemy as sa
# revision identifiers, used by Alembic.
revision: str = 'f91c39ca4f32'
down_revision: Union[str, None] = '10ec9562f6b3'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None
def upgrade() -> None:
    pass
def downgrade() -> None:
    pass
</file>

<file path="v2/alembic/env.py">
from logging.config import fileConfig
from sqlalchemy import engine_from_config
from sqlalchemy import pool
from dotenv import load_dotenv
from pathlib import Path
import sys, os
from alembic import context
# Path operations
parent = Path(__file__).resolve().parents[2]
load_dotenv(parent / '.env')
sys.path.append(str(parent))
# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config
# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)
from models.base import Base
target_metadata = Base.metadata
# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.
section = config.config_ini_section
config.set_section_option(section, "DATABASE_URL", os.getenv("DATABASE_URL"))
def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.
    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.
    Calls to context.execute() here emit the given string to the
    script output.
    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )
    with context.begin_transaction():
        context.run_migrations()
def run_migrations_online() -> None:
    """Run migrations in 'online' mode.
    In this scenario we need to create an Engine
    and associate a connection with the context.
    """
    connectable = engine_from_config(
        config.get_section(config.config_ini_section, {}),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )
        with context.begin_transaction():
            context.run_migrations()
if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
</file>

<file path="v2/alembic/README">
Generic single-database configuration.
</file>

<file path="v2/alembic/script.py.mako">
"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    ${downgrades if downgrades else "pass"}
</file>

<file path="v2/auth/functions.py">
from v2.models import storage
from v2.models.User import User
from v2.models.Profile import Profile
from datetime import datetime
from jose import jwt
from os import environ
SECRET_KEY = environ.get('SECRET_KEY')
ALGORITHM = environ.get('ALGORITHM')
def get_user_by_email(email: str) -> dict:
    """ Get a user by email """
    user = storage.session.query(User).filter(User.email == email).first()
    if user:
        profile = storage.session.query(Profile).filter(Profile.user_id == user.id).first()
    if user and profile:
        user_dict = user.to_dict()
        profile_dict = profile.to_dict()
        # Ensure we keep the user's ID, not the profile's
        profile_dict['id'] = user_dict['id']
        return {**user_dict, **profile_dict}
    return {}
def get_user_by_username(username: str) -> dict:
    """ Get a user by username """
    user = storage.session.query(Profile).filter(Profile.username == username).first()
    if user:
        profile = storage.session.query(Profile).filter(Profile.user_id == user.id).first()
    return {
        **user.to_dict(),
        **profile.to_dict()
    } if user and profile else {}
def get_user_by_id(user_id: str) -> User:
    """ Get a user by id """
    return storage.session.query(User).filter(User.id == user_id).first()
def create_access_token(email: str, id: str, expires_delta: datetime):
    """ Create an access token """
    expire = datetime.now() + expires_delta
    encode = {
        'email': email,
        'id': id,
        'exp': expire.timestamp() 
    }
    return jwt.encode(encode, SECRET_KEY, algorithm=ALGORITHM)
</file>

<file path="v2/auth/index.py">
""" Handles authentication """
from v2 import router
from flask import jsonify, request, abort, Blueprint
from v2.models.User import User
from v2.models.Profile import Profile
from flasgger.utils import swag_from
from passlib.context import CryptContext
from datetime import timedelta, datetime
from sqlalchemy.exc import IntegrityError
from os import environ
from v2.auth.functions import get_user_by_email, get_user_by_id, create_access_token, get_user_by_username
from v2.auth.validation import LoginRequest, SignupRequest
from v2.models import storage
from v2.utils.middleware import auth_middleware
# Create a Blueprint for auth routes
auth_router = Blueprint('auth', __name__, url_prefix='/api/auth')
secret_key = environ.get('SECRET_KEY')
algorithm = environ.get('ALGORITHM')
bcrypt_context = CryptContext(
    schemes=['bcrypt'],
    deprecated='auto',
    bcrypt__default_rounds=12 
)
@auth_router.route('/login', methods=['POST'], strict_slashes=False)
@swag_from('auth/login.yml', methods=['POST'])
def login():
    """ Login a user """
    try:
        data = request.get_json() if request.is_json else request.form
        login_data = LoginRequest.model_validate(data)
    except ValueError as e:
        return jsonify({ 'message': str(e) }), 400
    user_from_db = get_user_by_email(login_data.email) or get_user_by_username(login_data.email)
    if not user_from_db:
        return jsonify({ 'message': "User not found!" }), 404
    if not bcrypt_context.verify(login_data.password, user_from_db['password']):
        return jsonify({ 'message': "Invalid password!" }), 401
    token = create_access_token(user_from_db['email'], user_from_db['id'], timedelta(minutes=20))
    return jsonify({
        'message': 'Login successful!',
        'data': {
            'token': token,
            'user': {
                'email': user_from_db['email'],
                'full_name': user_from_db['full_name'],
                'id': user_from_db['id'],
                'unique_id': user_from_db['unique_id'],
                'total_productive_time': user_from_db['total_productive_time'],
                'total_wasted_time': user_from_db['total_wasted_time'],
                'weekly_work_hours_goal': user_from_db['weekly_work_hours_goal'],
                'number_of_work_days': user_from_db['number_of_work_days'],
                'username': user_from_db['username'],
                'profile_picture_url': user_from_db['profile_picture_url'],
                'bio': user_from_db['bio'],
                'location': user_from_db['location']
            }
        }
    }), 200
@auth_router.route('/signup', methods=['POST'], strict_slashes=False)
@swag_from('auth/signup.yml', methods=['POST'])
def signup():
    """ Signup a user """
    try:
        data = request.get_json() if request.is_json else request.form
        signup_data = SignupRequest.model_validate(data)
    except ValueError as e:
        return jsonify({ 'message': str(e) }), 400
    # First check if user already exists
    existing_user = get_user_by_email(signup_data.email)
    if existing_user:
        return jsonify({ 'message': "User with this email already exists!" }), 400
    try:
        hashed_password = bcrypt_context.hash(signup_data.password)
        # Create and save the user first
        new_user = User(
            email=signup_data.email,
            password=hashed_password
        )
        new_user.save()
        # Now create and save the profile
        new_profile = Profile(
            user_id=new_user.id,
            full_name=signup_data.full_name,
            username=signup_data.username,
            weekly_work_hours_goal=signup_data.weekly_work_hours_goal,
            number_of_work_days=signup_data.number_of_work_days,
            total_productive_time=0,
            total_wasted_time=0,
            profile_picture_url="",
            bio="",
            location=""
        )
        new_profile.save()
    except IntegrityError as e:
        storage.rollback()
        return jsonify({ 'message': "Username already exists!" }), 400
    except Exception as e:
        storage.rollback()
        return jsonify({ 'message': str(e) }), 500
    return jsonify({ 'message': 'User signed up successfully!'}), 200
@auth_router.route('/me', methods=['GET'], strict_slashes=False)
@auth_middleware
def get_current_user():
    """Get the current authenticated user's profile"""
    user = request.user
    # Create a serializable dictionary with user data
    user_data = {
        'email': user['email'],
        'full_name': user['full_name'],
        'id': user['unique_id'],
        'username': user['username'],
    }
    return jsonify({
        'message': 'User retrieved successfully',
        'data': user_data
    }), 200
</file>

<file path="v2/auth/validation.py">
from typing_extensions import Annotated
from pydantic import BaseModel, EmailStr, Field, field_validator
class LoginRequest(BaseModel):
    email: EmailStr
    password: str
    @field_validator('password')
    def password_validator(cls, v):
        if not v.strip():
            raise ValueError('Password cannot be empty')
        return v
class SignupRequest(BaseModel):
    email: EmailStr
    full_name: str
    password: str
    username: str
    weekly_work_hours_goal: Annotated[int, Field(gt=0)]  # positive integer
    number_of_work_days: Annotated[int, Field(ge=1, le=7)]  # integer between 1 and 7
    @field_validator('username')
    def username_validator(cls, v):
        if not v.strip():
            raise ValueError('Username cannot be empty')
        return v
    @field_validator('password')
    def password_length_validator(cls, v):
        if len(v) < 8:
            raise ValueError('Password must be at least 8 characters long')
        return v
</file>

<file path="v2/engine/storage.py">
#!/usr/bin/env python3
''' Handles the database storage for TimeCraft '''
import os
import sys
import sqlalchemy
from sqlalchemy import (create_engine, update)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
from v2.models.base import Base
from v2.models.User import User
from v2.models.Activity import Activity
from v2.models.Report import Report
from contextlib import contextmanager
from dotenv import load_dotenv
load_dotenv()  # Load environment variables from .env file
DATABASE_URL = os.getenv("DATABASE_URL")
if DATABASE_URL is None:
   raise ValueError("No DATABASE_URL found in environment variables")
class Storage:
    ''' This class defines handles the storage of our data '''
    __engine = None
    session = None
    user_id = None
    def __init__(self):
        ''' Insantization '''
        # We are using the dev database
        # self.__engine = create_engine(DATABASE_URL)
        #         # We are using the dev database
        self.__engine = create_engine(DATABASE_URL)
    def all_tasks(self, usr):
        ''' Query the current databse session all tasks belonging to the user
        '''
        task_list = []
        # Converts the string into the corresponding object
        if type(usr) is str:
            usr = eval(usr)
        usr_id = usr.id
        # Gets all Tasks in storage
        activities = self.session.query(Activity).filter(Activity.id == usr_id)
        # Filter the tasks assigned to our user
        # for task in tasks:
        #     if task.user_id == usr_id:
        #         task_list.append(task)
        return activities
    def total_time_on_task(self, usr, activity):
        ''' Gets the total time spent across all tasks OR
            total time spent on one task if task is specified '''
        activities = self.all_tasks(usr)
        total_time_on_task = 0
        # Goes through all the tasks related to the user
        for act in activities:
            if act.id == activity.id:
                return act.total_time_on_task
        return total_time_on_task
    def get_user(self, user_id=None):
        """ Get a user(Users) from the list of users """
        # Get all User objects in storage
        users = self.session.query(User)
        if user_id:
            for user in users:
                if user.unique_id == user_id:
                    return user
            return None
        # If no User Id given, return all User objects(for internal usage)
        return users
    def get_user_by_email(self, email):
        ''' Get user byy email address '''
        return self.session.query(User).filter(User.email == email).first()
    def get_task(self, task_id=None):
        """ Get a task(or all tasks) from the list of tasks """
        # Get all Task objects in storage
        activities = self.session.query(Activity)
        if activity_id:
            for activity in activities:
                if activity.unique_id == activity_id:
                    return activity
            return None
        # If noto Task ID is given, return all Task objects(for internal use)
        return activities
    def get_task_by_user_id(self, user_id):
        ''' Get a task by user Id '''
        return self.session.query(Activity).filter(Activity.user_id == user_id)
    def get_task_id_by_task_name(self, task_name):
        ''' Get task's Id by task name'''
        return self.session.query(Activity).filter(Activity.task_name == task_name).first().unique_id
    def get_logs_of_the_day(self, log_date=None):
        """ Gets a log(or all logs) from the list of logs """
        # Get all Log objects in storarge
        logs = self.session.query(Report)
        logs_of_the_day = []
        if log_date:
            for log in logs:
                # Get all logs for a given date
                if log.date == log_date:
                    logs_of_the_day.append(log)
            return logs_of_the_day
        # If no log date given, return all DailyLog objects(for internal use)
        return logs
    def new(self, obj):
        ''' Adds a new object to the session '''
        self.session.add(obj)
    def set_user_id(self, user_id):
        ''' Sets a user id for the session '''
        self.user_id = user_id
    def change_username(self, username, user_id):
        ''' Change username of a user '''
        update_query = (
            update(User)
            .where(User.unique_id == user_id)
            .values(username=username)
        )
        with self.session as session:
            session.execute(update_query)
            session.commit()
    def change_task_name(self, new_name, task_id):
        ''' Change task name of a task '''
        update_query = (
            update(Activity)
            .where(Activity.unique_id == activity_id)
            .values(task_name = new_name)
        )
        with self.session as session:
            session.execute(update_query)
            session.commit()
    def save(self):
        ''' Saves all changes made in the session '''
        self.session.commit()
    def delete(self, obj):
        ''' Deletes an object from the database '''
        if obj:
            # with self.session as session:
            self.session.delete(obj)
    def reload(self):
        ''' Creates all tables in the database and the current db session '''
        Base.metadata.create_all(self.__engine)
        session_factory = sessionmaker(bind=self.__engine,
                                       expire_on_commit=False)
        Session = scoped_session(session_factory)
        # Starts the session
        self.session = Session()
    def rollback(self):
        ''' Roll back the current session in case of error '''
        self.session.rollback()
    def close(self):
        ''' Closes the current session '''
        self.session.close()
</file>

<file path="v2/models/__init__.py">
#!/usr/bi/python3
''' Initialization model creates a storage object '''
from v2.engine.storage import Storage
storage = Storage()
storage.reload()
</file>

<file path="v2/models/Activity.py">
''' This module contains the class Activity '''
from v2.models.Basemodel import BaseModel
from v2.models.base import Base
from v2.models.Profile import Profile
from sqlalchemy import Column, String, Float, ForeignKey, DateTime
from sqlalchemy.orm import relationship
class Activity(BaseModel, Base):
    ''' This class is the represantation for the Task object '''
    __tablename__ = "activity"
    name = Column(String(128), nullable=False)
    description = Column(String(1024), nullable=True)
    total_time_on_task = Column(Float, nullable=False, default=0)
    daily_goal = Column(Float, nullable=False)
    weekly_goal = Column(Float, nullable=False)
    user_id = Column(String(60), ForeignKey("profile.user_id", ondelete="CASCADE"), nullable=False)
    user = relationship("Profile", back_populates="activities", foreign_keys=[user_id])
    reports = relationship("Report", back_populates="activity", cascade="all, delete-orphan")
    deleted = Column(DateTime, nullable=True)
</file>

<file path="v2/models/base.py">
from sqlalchemy.orm import declarative_base
Base = declarative_base()
</file>

<file path="v2/models/Basemodel.py">
""" This module contains the SQLAlchemy BaseModel """
import uuid
import string
import secrets
from v2 import models
from datetime import datetime
from sqlalchemy import String, Column, DateTime
from v2.models.base import Base
from sqlalchemy.ext.declarative import declared_attr
from sqlalchemy.ext.declarative import AbstractConcreteBase
class BaseModel(AbstractConcreteBase):
    """ This class is the base model for all models in the project """
    @declared_attr
    def __tablename__(cls):
        return cls.__name__.lower()
    @declared_attr
    def id(cls):
        return Column(String(60), primary_key=True)
    @declared_attr
    def created_at(cls):
        return Column(DateTime, nullable=False, default=datetime.now())
    @declared_attr
    def updated_at(cls):
        return Column(DateTime, nullable=False, default=datetime.now())
    @declared_attr
    def unique_id(cls):
        return Column(String(8), unique=True)
    def __generate_id__(self, length=8):
        """ Creates an 8 digit secure ID """
        chars = string.ascii_lowercase + string.digits
        return ''.join(secrets.choice(chars) for _ in range(length))
    def __init__(self, **kwargs):
        """ Instantiates a new model """
        # Set core fields with defaults
        self.id = str(uuid.uuid4())
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        self.unique_id = self.__generate_id__()
        # Filter out protected attributes from kwargs
        protected = {'id', 'created_at', 'updated_at', 'unique_id'}
        filtered_kwargs = {k: v for k, v in kwargs.items() if k not in protected}
        super().__init__(**filtered_kwargs)
    def __str__(self):
        """ Returns a string representation of the model """
        filtered_dict = {k: v for k, v in self.__dict__.items() if v}
        return f'[{type(self).__name__}] ({self.id}) {filtered_dict}'
    def save(self):
        """ Saves the model to the database """
        self.updated_at = datetime.now()
        models.storage.new(self)
        models.storage.save()
    def to_dict(self):
        """ Converts the model to a dictionary """
        dictionary = {}
        for key, value in self.__dict__.items():
            if value is not None:
                if isinstance(value, datetime):
                    dictionary[key] = value.isoformat()
                else:
                    dictionary[key] = value
        dictionary['__class__'] = self.__class__.__name__
        return dictionary
    def delete(self):
        """ Deletes the model from the database """
        models.storage.delete(self)
</file>

<file path="v2/models/Profile.py">
#!/usr/bin/env python3
''' This module contains the class User '''
from v2.models.Basemodel import BaseModel
from v2.models.base import Base
from v2.models.User import User
from sqlalchemy import Column, ForeignKey, String, Float, Integer, DateTime
from sqlalchemy.orm import relationship
class Profile(BaseModel, Base):
    ''' This class is the representation for the Profile object '''
    __tablename__ = "profile"
    user_id = Column(String(60), ForeignKey('user.id'), nullable=False, unique=True)
    full_name = Column(String(128), nullable=False)
    username = Column(String(128), nullable=False, unique=True)
    profile_picture_url = Column(String(256), nullable=False)
    bio = Column(String(256), nullable=False)
    location = Column(String(128), nullable=False)
    weekly_work_hours_goal = Column(Float, nullable=False)
    number_of_work_days = Column(Integer, nullable=False)
    total_productive_time = Column(Float, nullable=False, default=0)
    total_wasted_time = Column(Float, nullable=False, default=0)
    activities = relationship("Activity", back_populates="user", primaryjoin="and_(Profile.user_id==Activity.user_id, Activity.deleted==None)")
    user = relationship("User", back_populates="profile", uselist=False)
    deleted = Column(DateTime, nullable=True)
</file>

<file path="v2/models/Report.py">
''' This module contains the class Report '''
from v2.models.Basemodel import BaseModel
from v2.models.base import Base
from sqlalchemy import Column, DateTime, String, Float, Integer, ForeignKey
from sqlalchemy.orm import relationship
import pytz
from datetime import datetime
class Report(BaseModel, Base):
    ''' This class is the represantation for the User object '''
    __tablename__ = "report"
    date = Column(DateTime(timezone=True), nullable=False)
    activity_id = Column(String(128), ForeignKey("activity.id"), nullable=False)
    time_on_task = Column(Float, nullable=False, default=0)
    time_wasted = Column(Float, nullable=False, default=0)
    comment = Column(String(255), nullable=True)
    activity = relationship("Activity", back_populates="reports")
    deleted = Column(DateTime, nullable=True)
    def __init__(self, **kwargs):
        """Initialize a new Report with timezone handling"""
        # Handle date timezone
        if 'date' in kwargs and kwargs['date'].tzinfo is None:
            kwargs['date'] = kwargs['date'].replace(tzinfo=pytz.UTC)
        super().__init__(**kwargs)
</file>

<file path="v2/models/User.py">
#!/usr/bin/env python3
''' This module contains the class User '''
from v2.models.Basemodel import BaseModel
from v2.models.base import Base
from sqlalchemy import Column, String, Float, Integer, Table, DateTime
from sqlalchemy.orm import relationship
class User(BaseModel, Base):
    ''' This class is the represantation for the User object '''
    __table_args__ = {'extend_existing': True}
    email = Column(String(128), nullable=True, unique=True)
    password = Column(String(255), nullable=True)
    profile = relationship("Profile", back_populates="user", uselist=False)
    deleted = Column(DateTime, nullable=True)
</file>

<file path="v2/report/__init__.py">
"""Report package initialization"""
</file>

<file path="v2/report/functions.py">
"""Database query functions for report operations"""
from sqlalchemy import DateTime
from v2.models import storage
from v2.models.Profile import Profile
from v2.models.Report import Report
from v2.models.Activity import Activity
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pytz
def get_activity_by_id(activity_id: str, user_id: str) -> Optional[Activity]:
    """Get an activity by ID and verify it belongs to the user"""
    return storage.session.query(Activity).filter(
        Activity.unique_id == activity_id,
        Activity.user_id == user_id,
        Activity.deleted.is_(None)
    ).first()
def get_profile_by_id(user_id: str) -> Optional[Profile]:
    """Get a profile by ID"""
    return storage.session.query(Profile).filter(
        Profile.user_id == user_id,
        Profile.deleted.is_(None)
    ).first()
def get_user_activities(user_id: str) -> List[Activity]:
    """Get all activities for a user"""
    return storage.session.query(Activity).filter(
        Activity.user_id == user_id,
        Activity.deleted.is_(None)
    ).all()
def get_activity_reports(
    activity: Activity,
    start_date: datetime,
    end_date: datetime
) -> List[Report]:
    """Get all reports for an activity within a date range"""
    reports = storage.session.query(Report).filter(
        Report.activity_id == activity.id,
        Report.deleted == None,
        Report.date.between(start_date, end_date)
    ).all()
    return reports
def create_new_report(
    activity: Activity,
    date: datetime,
    time_on_task: float,
    time_wasted: float,
    comment: Optional[str] = None
) -> Report:
    """Create a new report and update activity stats"""
    new_report = Report(
        activity_id=activity.id,
        date=date,
        time_on_task=time_on_task,
        time_wasted=time_wasted,
        comment=comment
    )
    try:
        # Update activity's total time
        activity.total_time_on_task += time_on_task
        # Save both report and updated activity
        new_report.save()
        activity.save()
        return new_report
    except Exception as e:
        storage.rollback()
        raise e
def get_reports_in_range(
    user_id: str,
    start_date: datetime,
    end_date: datetime
) -> Dict:
    """Get all reports within a date range grouped by activity"""
    # Get all activities for the user
    activities = get_user_activities(user_id)
    # Initialize response data
    total_productive_time = 0
    total_wasted_time = 0
    activities_data = {}
    # For each activity, get and process its reports
    for activity in activities:
        reports = get_activity_reports(activity, start_date, end_date)
        if reports:
            productive_time = sum(report.time_on_task for report in reports)
            wasted_time = sum(report.time_wasted for report in reports)
            # Update totals
            total_productive_time += productive_time
            total_wasted_time += wasted_time
            # Add to activities data
            activities_data[activity.name] = {
                'total_time_on_task': productive_time,
                'total_time_wasted': wasted_time,
            }
    # Create final response
    return {
        'start_date': start_date,
        'end_date': end_date,
        'total_productive_time': total_productive_time,
        'total_wasted_time': total_wasted_time,
        'activities': activities_data
    }
def format_dates(start_date: str | None, end_date: str | None) -> tuple[datetime, datetime]:
    """Format start and end dates for report queries
    If no dates provided, defaults to today.
    If only start_date, end_date will be start_date + 1 day.
    Dates should be in YYYY-MM-DD format.
    Returns:
        Tuple of (start_date, end_date) as UTC datetimes
    """
    # If no dates provided, use today as default
    if not start_date and not end_date:
        end_date = datetime.now(pytz.UTC).replace(
            hour=23, minute=59, second=59, microsecond=999999
        )
        start_date = end_date.replace(
            hour=0, minute=0, second=0, microsecond=0
        )
        return start_date, end_date
    # Parse date strings (expecting YYYY-MM-DD format)
    if not start_date:
        raise ValueError('start_date is required if end_date is provided')
    start = datetime.strptime(start_date, '%Y-%m-%d').replace(
        hour=0, minute=0, second=0, microsecond=0, tzinfo=pytz.UTC
    )
    if end_date:
        end = datetime.strptime(end_date, '%Y-%m-%d').replace(
            hour=23, minute=59, second=59, microsecond=999999, tzinfo=pytz.UTC
        )
    else:
        # If no end_date provided, set it to one day after start_date
        end = start + timedelta(days=1)
    return start, end
</file>

<file path="v2/report/index.py">
"""Report routes"""
from v2 import router
from flask import jsonify, request
from v2.utils.middleware import auth_middleware
from v2.report.validation import CreateReportRequest
from v2.report.functions import (
    format_dates,
    get_activity_by_id,
    create_new_report,
    get_profile_by_id,
    get_reports_in_range
)
@router.route('/report', methods=['POST'])
@auth_middleware
def create_report():
    """Create a new report for an activity"""
    try:
        # Validate request data
        data = request.get_json() if request.is_json else request.form
        report_data = CreateReportRequest.model_validate(data)
        # Verify the activity exists and belongs to the user
        activity = get_activity_by_id(report_data.activity_id, request.user['id'])
        if not activity:
            return jsonify({
                'message': 'Activity not found'
            }), 404
        # Create new report
        new_report = create_new_report(
            activity=activity,
            date=report_data.date,
            time_on_task=report_data.time_on_task,
            time_wasted=report_data.time_wasted,
            comment=report_data.comment
        )
        profile = get_profile_by_id(request.user['id'])
        profile.total_productive_time = profile.total_productive_time + report_data.time_on_task
        profile.total_wasted_time = profile.total_wasted_time + report_data.time_wasted
        profile.save()
        # Use ReportResponse for serialization
        # report_response = ReportResponse.model_dump(new_report)
        return jsonify({
            'message': 'Report created successfully',
            'data': {
                'id': new_report.id,
                'unique_id': new_report.unique_id,
                'activity_id': new_report.activity_id,
                'date': new_report.date,
                'time_on_task': new_report.time_on_task,
                'time_wasted': new_report.time_wasted,
                'comment': new_report.comment
            }
        }), 201
    except ValueError as e:
        return jsonify({'message': str(e)}), 400
    except Exception as e:
        return jsonify({'message': str(e)}), 500
@router.route('/report', methods=['GET'])
@auth_middleware
def get_report():
    """Get all reports within a date range grouped by activity"""
    try:
        try:
            start_date, end_date = format_dates(
                request.args.get('start_date'),
                request.args.get('end_date')
            )
            # Validate date range
            if end_date < start_date:
                return jsonify({
                    'message': 'end_date cannot be before start_date'
                }), 400
            # Limit the date range to prevent excessive queries
            max_days = 366  # Maximum one year of data
            if (end_date - start_date).days > max_days:
                return jsonify({
                    'message': 'Date range cannot exceed a year'
                }), 400
        except ValueError:
            return jsonify({
                'message': 'Invalid date format. Use YYYY-MM-DD'
        }), 400
        # Get reports within date range
        reports = get_reports_in_range(
            user_id=request.user['id'],
            start_date=start_date,
            end_date=end_date
        )
        return jsonify({
            'message': 'Reports retrieved successfully',
            'data': reports
        }), 200
    except Exception as e:
        return jsonify({'message': str(e)}), 500
</file>

<file path="v2/report/validation.py">
"""Report validation schemas"""
from pydantic import BaseModel, Field, field_validator
from datetime import datetime
import pytz
from typing import Dict, List
class CreateReportRequest(BaseModel):
    """Validation schema for report creation"""
    activity_id: str = Field(..., min_length=1)
    date: datetime
    time_on_task: float = Field(..., ge=0)
    time_wasted: float = Field(..., ge=0)
    comment: str | None = Field(None, max_length=255)
    @field_validator('date')
    @classmethod
    def validate_date(cls, v: datetime) -> datetime:
        # Convert naive datetime to UTC if no timezone is provided
        if v.tzinfo is None:
            v = v.replace(tzinfo=pytz.UTC)
        # Compare with current UTC time
        now = datetime.now(pytz.UTC)
        if v > now:
            raise ValueError("Report date cannot be in the future")
        return v
class ReportResponse(BaseModel):
    """Schema for individual report in response"""
    id: str
    unique_id: str
    activity_id: str
    date: datetime
    time_on_task: float
    time_wasted: float
    comment: str | None
class ActivityDailyStats(BaseModel):
    """Schema for daily activity statistics"""
    activity_name: str
    total_time_on_task: float
    total_time_wasted: float
class DailyReportResponse(BaseModel):
    """Schema for complete daily report response"""
    date: datetime
    total_productive_time: float
    total_wasted_time: float
    activities: Dict[str, ActivityDailyStats]
</file>

<file path="v2/utils/middleware.py">
"""Authentication middleware for Flask endpoints"""
from functools import wraps
from flask import request, abort, jsonify
from jose import JWTError, jwt
from os import environ
from v2.models import storage
from v2.auth.functions import get_user_by_email
def auth_middleware(f):
    """Decorator to protect routes that require authentication
    Usage:
        @router.route('/protected-route')
        @token_required
        def protected_endpoint():
            # Your code here
            pass
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        token = None
        # Get token from header
        auth_header = request.headers.get('Authorization')
        if not auth_header:
            abort(401, description="Authorization header is missing")
        if not auth_header.startswith('Bearer '):
            abort(401, description="Invalid token format. Must be 'Bearer <token>'")
        token = auth_header.split(' ')[1]
        try:
            # Decode the token
            payload = jwt.decode(
                token,
                environ.get('SECRET_KEY'),
                algorithms=[environ.get('ALGORITHM')]
            )
            # Get user from database
            current_user = get_user_by_email(payload.get('email'))
            if not current_user:
                abort(401, description="Invalid token: User not found")
            # Add user to request context
            request.user = current_user
        except JWTError:
            abort(401, description="Invalid or expired token")
        except Exception as e:
            abort(500, description=str(e))
        return f(*args, **kwargs)
    return decorated
</file>

<file path="v2/__init__.py">
#!/usr/bin/python3
""" Blueprint for API """
from flask import Blueprint, jsonify
# Create the blueprint
router = Blueprint('actions', __name__)
# Import all the views(actions)
from v2.auth.index import *
from v2.activity.index import *
from v2.report.index import *
# Add a test route to verify blueprint is working
@router.route('/', methods=['GET'])
def test():
    return jsonify({"TimeCraft API": "API is working!"})
</file>

<file path="v2/.gitignore">
__pycache__/
</file>

<file path="v2/alembic.ini">
# A generic, single database configuration.

[alembic]
# path to migration scripts
# Use forward slashes (/) also on windows to provide an os agnostic path
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
# version_path_separator = newline
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url = %(DATABASE_URL)s


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
</file>

<file path="v2/app.py">
#!/usr/bin/python3
""" Flask App """
from v2.models import storage
from os import environ
from flask import Flask, make_response, jsonify
from flask_cors import CORS
from flasgger import Swagger
from . import router
from v2.auth.index import auth_router
# Initializing app
app = Flask(__name__)
app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True
# Registering blueprint on app
app.register_blueprint(router, url_prefix="/api")
app.register_blueprint(auth_router)
# Setting up Cross-Origin-Resource-Sharing properly
CORS(app, resources={r"/api/*": {"origins": "*"}})
# Closes the Database session when necessary
@app.teardown_appcontext
def close_db(error):
    """ Terminate database session """
    storage.close()
# Handles 404 errors
@app.errorhandler(404)
def not_found(error):
    """ 404 Error
    ---
    response:
      404:
        description: a resource was not found
    """
    return make_response(jsonify({'error': "NOT FOUND"}), 404)
# Documentation tool
app.config['SWAGGER'] = {
    'title': 'TimeCraft',
    'uiversion': 3
}
Swagger(app)
# Run the Flask app
if __name__ == "__main__":
    """ Main Function """
    host = environ.get('HBNB_API_HOST', '0.0.0.0')
    port = environ.get('HBNB_API_PORT', 5000)
    app.run(host=host, port=int(port), threaded=True, debug=True)
</file>

<file path="v2/index.py">
from . import router
from flask import jsonify
@router.route('/', methods=['GET'], strict_slashes=False)
def index():
    return jsonify({"TimeCraft API": "OK"})
</file>

<file path="v2/pyproject.toml">
[project]
name = "backend"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "alembic>=1.14.1",
    "bcrypt>=4.2.1",
    "dotenv>=0.9.9",
    "flasgger>=0.9.7.1",
    "flask-cors>=5.0.0",
    "flask[standard]>=3.1.0",
    "mysqlclient>=2.2.7",
    "passlib>=1.7.4",
    "psycopg2>=2.9.10",
    "pydantic[email,timezone]>=2.10.6",
    "python-jose>=3.4.0",
    "pytz>=2025.1",
    "sqlalchemy>=2.0.38",
    "uvicorn>=0.34.0",
]
</file>

<file path=".cursorrules">
<cursor-tools Integration>
# Instructions
Use the following commands to get AI assistance:

**Web Search:**
`cursor-tools web "<your question>"` - Get answers from the web using Perplexity AI (e.g., `cursor-tools web "latest weather in London"`)
when using web for complex queries suggest writing the output to a file somewhere like local-research/<query summary>.md.

**Repository Context:**
`cursor-tools repo "<your question>"` - Get context-aware answers about this repository using Google Gemini (e.g., `cursor-tools repo "explain authentication flow"`)

**Documentation Generation:**
`cursor-tools doc [options]` - Generate comprehensive documentation for this repository (e.g., `cursor-tools doc --output docs.md`)
when using doc for remote repos suggest writing the output to a file somewhere like local-docs/<repo-name>.md.

**GitHub Information:**
`cursor-tools github pr [number]` - Get the last 10 PRs, or a specific PR by number (e.g., `cursor-tools github pr 123`)
`cursor-tools github issue [number]` - Get the last 10 issues, or a specific issue by number (e.g., `cursor-tools github issue 456`)

**Browser Automation (Stateless):**
`cursor-tools browser open <url> [options]` - Open a URL and capture page content, console logs, and network activity (e.g., `cursor-tools browser open "https://example.com" --html`)
`cursor-tools browser act "<instruction>" --url=<url> [options]` - Execute actions on a webpage using natural language instructions (e.g., `cursor-tools browser act "Click Login" --url=https://example.com`)
`cursor-tools browser observe "<instruction>" --url=<url> [options]` - Observe interactive elements on a webpage and suggest possible actions (e.g., `cursor-tools browser observe "interactive elements" --url=https://example.com`)
`cursor-tools browser extract "<instruction>" --url=<url> [options]` - Extract data from a webpage based on natural language instructions (e.g., `cursor-tools browser extract "product names" --url=https://example.com/products`)

**Notes on Browser Commands:**
- All browser commands are stateless: each command starts with a fresh browser instance and closes it when done.
- When using `--connect-to`, special URL values are supported:
  - `current`: Use the existing page without reloading
  - `reload-current`: Use the existing page and refresh it (useful in development)
- Multi step workflows involving state or combining multiple actions are supported in the `act` command using the pipe (|) separator (e.g., `cursor-tools browser act "Click Login | Type 'user@example.com' into email | Click Submit" --url=https://example.com`)
- Video recording is available for all browser commands using the `--video=<directory>` option. This will save a video of the entire browser interaction at 1280x720 resolution. The video file will be saved in the specified directory with a timestamp.
- DO NOT ask browser act to "wait" for anything, the wait command is currently disabled in Stagehand.

**Tool Recommendations:**
- `cursor-tools web` is best for general web information not specific to the repository.
- `cursor-tools repo` is ideal for repository-specific questions, planning, code review and debugging.
- `cursor-tools doc` generates documentation for local or remote repositories.
- `cursor-tools browser` is useful for testing and debugging web apps.

**Running Commands:**
1. **Installed version:** Use `cursor-tools <command>` (if in PATH) or `npm exec cursor-tools "<command>"`, `yarn cursor-tools "<command>"`, `pnpm cursor-tools "<command>"`.
2. **Without installation:** Use `npx -y cursor-tools@latest "<command>"` or `bunx -y cursor-tools@latest "<command>"`.

**General Command Options (Supported by all commands):**
--model=<model name>: Specify an alternative AI model to use
--max-tokens=<number>: Control response length
--save-to=<file path>: Save command output to a file (in *addition* to displaying it)
--help: View all available options (help is not fully implemented yet)

**Documentation Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Generate documentation for a remote GitHub repository

**GitHub Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Access PRs/issues from a specific GitHub repository

**Browser Command Options (for 'open', 'act', 'observe', 'extract'):**
--console: Capture browser console logs (enabled by default, use --no-console to disable)
--html: Capture page HTML content
--network: Capture network activity (enabled by default, use --no-network to disable)
--screenshot=<file path>: Save a screenshot of the page
--timeout=<milliseconds>: Set navigation timeout (default: 30000ms)
--viewport=<width>x<height>: Set viewport size (e.g., 1280x720). When using --connect-to, viewport is only changed if this option is explicitly provided
--headless: Run browser in headless mode (default: true)
--no-headless: Show browser UI (non-headless mode) for debugging
--connect-to=<port>: Connect to existing Chrome instance
--wait=<duration or selector>: Wait after page load (e.g., '5s', '#element-id', 'selector:.my-class')
--video=<directory>: Save a video recording of the browser interaction to the specified directory (1280x720 resolution). Not available when using --connect-to

**Additional Notes:**
- For detailed information, see `node_modules/cursor-tools/README.md` (if installed locally).
- Configuration is in `cursor-tools.config.json` (or `~/.cursor-tools/config.json`).
- API keys are loaded from `.cursor-tools.env` (or `~/.cursor-tools/.env`).
- Browser commands require separate installation of Playwright: `npm install --save-dev playwright` or `npm install -g playwright`.
- **Remember:** You're part of a team of superhuman expert AIs. Work together to solve complex problems.
<!-- cursor-tools-version: 0.5.0 -->
</cursor-tools Integration>
</file>

<file path=".gitignore">
.env
__pychache__
</file>

<file path=".python-version">
3.13
</file>

<file path="alembic.ini">
# A generic, single database configuration.

[alembic]
# path to migration scripts
# Use forward slashes (/) also on windows to provide an os agnostic path
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
# version_path_separator = newline
version_path_separator = os  # Use os.pathsep. Default configuration used for new projects.

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url =


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
</file>

<file path="package.json">
{
  "devDependencies": {
    "cursor-tools": "latest"
  }
}
</file>

<file path="tc_dev_db_backup.sql">
-- MariaDB dump 10.19-11.3.2-MariaDB, for Linux (x86_64)
--
-- Host: localhost    Database: tc_dev_db
-- ------------------------------------------------------
-- Server version	11.3.2-MariaDB
/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;
--
-- Table structure for table `daily_log`
--
DROP TABLE IF EXISTS `daily_log`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `daily_log` (
  `id` varchar(60) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `month` varchar(60) NOT NULL,
  `day` int(11) NOT NULL,
  `year` int(11) NOT NULL,
  `task_id` varchar(128) NOT NULL,
  `time_on_task` float NOT NULL,
  `time_wasted` float NOT NULL,
  `day_of_week` varchar(55) NOT NULL,
  `date` varchar(255) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `task_id` (`task_id`),
  CONSTRAINT `daily_log_ibfk_1` FOREIGN KEY (`task_id`) REFERENCES `tasks` (`id`) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;
--
-- Dumping data for table `daily_log`
--
LOCK TABLES `daily_log` WRITE;
/*!40000 ALTER TABLE `daily_log` DISABLE KEYS */;
INSERT INTO `daily_log` VALUES
('00558a62-358c-4259-bf51-dacde836b77f','2024-06-22 18:11:58','2024-06-22 18:11:58','June',22,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.67,2,'Saturday','June.22.2024'),
('009b11ff-3af7-4288-b0df-d38ab03b21e4','2024-09-28 22:26:18','2024-09-28 22:26:18','September',28,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',3.33,0.66,'Saturday','September.28.2024'),
('02e71ba2-f6ff-4fbf-88cd-cf3c6ed0f70f','2024-04-24 23:12:17','2024-04-24 23:12:17','April',24,2024,'521c1037-04c1-4120-8a73-713b742319c9',3.5,2,'2','April.24.2024'),
('03c0bbcc-218c-4d22-9e42-2eed5954cf2e','2024-09-19 16:25:24','2024-09-19 16:25:24','September',19,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',1.33,0.5,'Thursday','September.19.2024'),
('04e7e917-faae-49e9-ac0a-95ed262fbd6c','2024-05-05 01:28:12','2024-05-05 01:28:12','May',5,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,4,'Sunday','May.5.2024'),
('05d018f1-d5d6-4947-8efb-167b2fdce08c','2024-05-15 17:56:46','2024-05-15 17:56:46','May',15,2024,'521c1037-04c1-4120-8a73-713b742319c9',2,3,'Wednesday','May.15.2024'),
('07d8b502-5e9c-45d5-85e6-fb5a85cdebd1','2024-08-28 17:41:19','2024-08-28 17:41:19','August',28,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',3.66,1,'Wednesday','August.28.2024'),
('07f7c881-6b6a-427f-8773-c637ba826358','2024-06-29 06:55:22','2024-06-29 06:55:22','June',29,2024,'521c1037-04c1-4120-8a73-713b742319c9',8,1.75,'Saturday','June.29.2024'),
('0a85a100-8422-4215-b050-95148ee9c5c0','2024-10-01 10:56:32','2024-10-01 10:56:32','October',1,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',9.33,3,'Tuesday','October.1.2024'),
('0f33bbb6-6bc7-44ca-a180-1adb6b518320','2024-06-13 20:55:58','2024-06-13 20:55:58','June',13,2024,'521c1037-04c1-4120-8a73-713b742319c9',4.9,3.5,'Thursday','June.13.2024'),
('1782906a-c8bb-4c88-90cd-0c8c73e6d302','2024-10-28 11:43:11','2024-10-28 11:43:11','October',28,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',2,1,'Monday','October.28.2024'),
('19d53cf0-cf08-4cdf-b695-62b4c10c9ac0','2024-05-11 15:10:16','2024-05-11 15:10:16','May',11,2024,'521c1037-04c1-4120-8a73-713b742319c9',1.5,2,'Saturday','May.11.2024'),
('19e70a42-c1bd-481e-94f7-69bdaadf2875','2024-08-17 08:57:48','2024-08-17 08:57:48','August',17,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',6,2,'Saturday','August.17.2024'),
('1a38be28-5930-470f-958c-c7dca823fdb9','2024-08-14 01:52:04','2024-08-14 01:52:04','August',14,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',4.5,1.75,'Wednesday','August.14.2024'),
('1cf31df2-dc77-4839-b7f3-fef5936cbb9e','2024-09-24 23:08:11','2024-09-24 23:08:11','September',24,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',3.5,1.42,'Tuesday','September.24.2024'),
('1e94131b-64c7-43f0-b8f3-096024efec0e','2024-05-29 20:47:27','2024-05-29 20:47:27','May',29,2024,'521c1037-04c1-4120-8a73-713b742319c9',4.25,1.34,'Wednesday','May.29.2024'),
('1f61e3ec-12f2-4624-b2f7-20fc166def95','2024-06-05 23:11:25','2024-06-05 23:11:25','June',5,2024,'521c1037-04c1-4120-8a73-713b742319c9',3.5,1.34,'Wednesday','June.5.2024'),
('217ee57c-24f1-45f4-9dc1-b8d367a837dd','2024-05-11 15:10:35','2024-05-11 15:10:35','May',11,2024,'521c1037-04c1-4120-8a73-713b742319c9',2,0,'Saturday','May.11.2024'),
('2499bde3-3890-4843-998f-dba231d25916','2024-10-21 21:40:43','2024-10-21 21:40:43','October',21,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',8.33,3.33,'Monday','October.21.2024'),
('29f9a077-f054-44ee-83ca-e0c6bc61599d','2024-06-11 18:04:31','2024-06-11 18:04:31','June',11,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.9,1.2,'Tuesday','June.11.2024'),
('317faa7e-6ce3-4141-8078-6e615a036323','2024-05-08 02:49:21','2024-05-08 02:49:21','May',8,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.67,2.5,'Wednesday','May.8.2024'),
('31a0b280-3afe-45b8-9189-94361938252a','2024-06-07 22:02:17','2024-06-07 22:02:17','June',7,2024,'521c1037-04c1-4120-8a73-713b742319c9',4,2.34,'Friday','June.7.2024'),
('32de155e-6339-4c44-988b-3d3210332f90','2024-10-02 14:33:06','2024-10-02 14:33:06','October',2,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',19.5,3,'Wednesday','October.2.2024'),
('3575f1a4-f605-4d6a-a32b-bf8213bcf927','2024-06-25 13:29:58','2024-06-25 13:29:58','June',25,2024,'521c1037-04c1-4120-8a73-713b742319c9',3.75,0.25,'1','June.25.2024'),
('37458a18-4773-485e-8909-9c3b5e514340','2024-05-09 02:45:22','2024-05-09 02:45:22','May',9,2024,'521c1037-04c1-4120-8a73-713b742319c9',7,3.67,'Thursday','May.9.2024'),
('387f9d7b-4739-471b-8d25-4499e04a73b3','2024-05-26 23:34:58','2024-05-26 23:34:58','May',26,2024,'521c1037-04c1-4120-8a73-713b742319c9',0,1,'Sunday','May.26.2024'),
('388461ab-f8f1-468a-a2bb-ada0870edbe0','2024-09-28 05:13:24','2024-09-28 05:13:24','September',28,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',6,3.66,'Saturday','September.28.2024'),
('3a45aca3-d326-4982-a6e9-e447a217d6d7','2024-06-10 21:19:03','2024-06-10 21:19:03','June',10,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.67,3,'Monday','June.10.2024'),
('3a78b849-58af-490d-be7d-c8fb5400638b','2024-05-19 16:48:10','2024-05-19 16:48:10','May',19,2024,'521c1037-04c1-4120-8a73-713b742319c9',2,1,'Sunday','May.19.2024'),
('3c62f3fd-07be-4c17-b280-58e362dbaa6d','2024-06-21 20:10:26','2024-06-21 20:10:26','June',21,2024,'521c1037-04c1-4120-8a73-713b742319c9',7.33,2.33,'4','June.21.2024'),
('3d8500aa-91bd-49a4-b322-1440d355b56a','2024-05-28 03:11:13','2024-05-28 03:11:13','May',28,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.75,3.5,'Tuesday','May.28.2024'),
('3e438f98-4187-46a7-9d33-597ca78083e8','2024-06-17 21:13:23','2024-06-17 21:13:23','June',17,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.25,2.9,'Monday','June.17.2024'),
('3ed6ecc0-dd0e-4a57-b369-50fc594785a9','2024-04-28 20:16:02','2024-04-28 20:16:02','April',28,2024,'521c1037-04c1-4120-8a73-713b742319c9',5,2,'6','April.28.2024'),
('401f8ede-c25a-40b7-8b76-417cd9779052','2024-08-23 19:01:11','2024-08-23 19:01:11','August',23,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',4.9,0.5,'Friday','August.23.2024'),
('42a57eeb-04fc-4897-8519-e016bf4034dc','2024-10-19 22:10:13','2024-10-19 22:10:13','October',19,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',2,3,'Saturday','October.19.2024'),
('44f3e9ad-0adf-4e66-8c5f-1898b946d66d','2024-08-10 19:29:48','2024-08-10 19:29:48','August',10,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',4.66,2.15,'Saturday','August.10.2024'),
('4993163f-2792-4fc5-b57f-c9c5642dcfda','2024-08-26 16:09:53','2024-08-26 16:09:53','August',26,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',2,1,'Monday','August.26.2024'),
('4d0fcf83-247a-4b70-9883-acef49dfbcd4','2024-04-25 21:55:30','2024-04-25 21:55:30','April',25,2024,'521c1037-04c1-4120-8a73-713b742319c9',0.5,7.5,'3','April.25.2024'),
('4e331046-68e6-46b7-999f-4d332668a782','2024-05-23 02:46:19','2024-05-23 02:46:19','May',23,2024,'521c1037-04c1-4120-8a73-713b742319c9',3.75,2.34,'Thursday','May.23.2024'),
('518108fe-a249-4fd9-bfa1-022079990873','2024-08-15 23:11:39','2024-08-15 23:11:39','August',15,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',2.66,1,'Thursday','August.15.2024'),
('547be73d-1e08-4734-b3bb-2aa11865c7b6','2024-09-27 05:51:24','2024-09-27 05:51:24','September',27,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',6,2.5,'Friday','September.27.2024'),
('5dd58f9c-6450-48ae-b3b5-4fc60d8f54d1','2024-09-05 14:11:10','2024-09-05 14:11:10','September',5,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',2,0.75,'Thursday','September.5.2024'),
('5e01b30f-4748-4aae-a958-8dce09457043','2024-07-01 08:57:53','2024-07-01 08:57:53','July',1,2024,'521c1037-04c1-4120-8a73-713b742319c9',3,0,'Monday','July.1.2024'),
('6210c397-edd0-4727-91ea-147f0b685c06','2024-08-08 18:34:21','2024-08-08 18:34:21','August',8,2024,'cf3c64c6-508c-4705-a2ce-5ab5230677f4',9.8,4,'Thursday','August.8.2024'),
('65d5fe5e-7f35-4ae6-a802-eb84780f5be4','2024-05-21 01:14:46','2024-05-21 01:14:46','May',21,2024,'521c1037-04c1-4120-8a73-713b742319c9',4,3,'Tuesday','May.21.2024'),
('65f18419-8034-4d1a-806e-5f76b74c9e4e','2024-05-28 21:10:30','2024-05-28 21:10:30','May',28,2024,'521c1037-04c1-4120-8a73-713b742319c9',2.5,1.34,'Tuesday','May.28.2024'),
('664baa27-2343-470a-89a6-2d140ba1121e','2024-06-25 20:31:14','2024-06-25 20:31:14','June',25,2024,'521c1037-04c1-4120-8a73-713b742319c9',2.9,1,'Tuesday','June.25.2024'),
('673b8686-c9f7-4a40-8ede-124be87f2376','2024-07-27 04:56:07','2024-07-27 04:56:07','July',27,2024,'521c1037-04c1-4120-8a73-713b742319c9',0,0,'Saturday','July.27.2024'),
('67ffdab1-f051-48e1-a5d9-5b5c2a24afd2','2024-04-26 23:37:31','2024-04-26 23:37:31','April',26,2024,'521c1037-04c1-4120-8a73-713b742319c9',2.3,0.2,'4','April.26.2024'),
('6a71a43f-24cf-4193-afc1-3744ad5eed73','2024-07-03 23:46:40','2024-07-03 23:46:40','July',3,2024,'521c1037-04c1-4120-8a73-713b742319c9',2.5,0.25,'Wednesday','July.3.2024'),
('6dfce77c-fb05-42e6-988b-37a22f98033e','2024-09-26 06:38:53','2024-09-26 06:38:53','September',26,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',6.42,2.66,'Thursday','September.26.2024'),
('6f5679e5-1faf-472d-9dc3-ad71ef720c7b','2024-06-01 21:44:08','2024-06-01 21:44:08','June',1,2024,'521c1037-04c1-4120-8a73-713b742319c9',5,2.34,'Saturday','June.1.2024'),
('6fdb2b46-102d-453c-98fb-ea27450015d9','2024-05-01 23:51:49','2024-05-01 23:51:49','May',1,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.3,2.75,'Wednesday','May.1.2024'),
('76baf414-e6c2-4381-8ac5-1fe0a607ae3d','2024-04-23 18:41:00','2024-04-23 18:41:00','April',23,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.67,4.5,'1','April.23.2024'),
('784d11b6-db1a-41bc-b9d7-7ed78736373e','2024-10-26 12:35:41','2024-10-26 12:35:41','October',26,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',1,0,'Saturday','October.26.2024'),
('7b5013a5-2043-4ca1-8541-46dfd02da04b','2024-05-26 23:34:45','2024-05-26 23:34:45','May',26,2024,'521c1037-04c1-4120-8a73-713b742319c9',0.75,1,'Sunday','May.26.2024'),
('7ee257c5-2038-4d48-80a7-22c59d7e1fc1','2024-06-18 21:54:46','2024-06-18 21:54:46','June',18,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.33,2.75,'Tuesday','June.18.2024'),
('835b43ba-5104-48a7-af01-b99d1376a6d0','2024-08-20 18:57:42','2024-08-20 18:57:42','August',20,2024,'e968804d-fd17-48fd-90a9-be82a84cfbd1',0.75,0,'Tuesday','August.20.2024'),
('84e33838-cee0-4595-98b5-604def2e9cb9','2024-05-24 02:23:12','2024-05-24 02:23:12','May',24,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,3,'Friday','May.24.2024'),
('86039fac-2427-4a84-bae4-c3ff9612830f','2024-09-28 09:58:21','2024-09-28 09:58:21','September',28,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',1,0.5,'Saturday','September.28.2024'),
('860bda7d-8e5f-4e4b-9715-1e4970d161f6','2024-06-03 21:27:48','2024-06-03 21:27:48','June',3,2024,'521c1037-04c1-4120-8a73-713b742319c9',5,4,'Monday','June.3.2024'),
('8adc06ff-c5a4-4d69-8703-5c77f057787e','2024-06-20 21:36:32','2024-06-20 21:36:32','June',20,2024,'521c1037-04c1-4120-8a73-713b742319c9',8.5,3,'Thursday','June.20.2024'),
('8d5f964f-6dbe-4e5f-98f7-b84e41eed2fd','2024-05-02 23:24:34','2024-05-02 23:24:34','May',2,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.75,2,'3','May.2.2024'),
('8f125579-dead-4f04-923a-8db20ba77d90','2024-08-31 00:43:04','2024-08-31 00:43:04','August',31,2024,'e968804d-fd17-48fd-90a9-be82a84cfbd1',4.33,3.33,'Saturday','August.31.2024'),
('8f66bf2b-8f33-492a-9d69-e3877de8a9e2','2024-06-19 21:50:29','2024-06-19 21:50:29','June',19,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.25,2.5,'Wednesday','June.19.2024'),
('8fd04bed-f8f3-482b-acb6-c9a0e8f10909','2024-06-23 21:51:53','2024-06-23 21:51:53','June',23,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,1,'6','June.23.2024'),
('90849415-1562-4d32-9a96-7d83ae22c4a4','2024-08-20 18:31:21','2024-08-20 18:31:21','August',20,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',4,1,'Tuesday','August.20.2024'),
('90b49651-76ca-4de6-9b74-88dccc43b0aa','2024-08-19 21:47:30','2024-08-19 21:47:30','August',19,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',6,1.5,'Monday','August.19.2024'),
('97b0b3e3-eba1-4f75-8560-aff0d98a8223','2024-05-31 21:34:28','2024-05-31 21:34:28','May',31,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,3.5,'Friday','May.31.2024'),
('994f81b7-4b59-4fc2-a2d4-9eb9fa50e8d2','2024-05-17 01:26:30','2024-05-17 01:26:30','May',17,2024,'521c1037-04c1-4120-8a73-713b742319c9',9.3,2,'Friday','May.17.2024'),
('9a3580e3-5a5e-476d-9bbb-e231c3d8668e','2024-05-18 04:10:08','2024-05-18 04:10:08','May',18,2024,'521c1037-04c1-4120-8a73-713b742319c9',3.75,2.5,'Saturday','May.18.2024'),
('9cb8e12e-7100-4405-98fe-05c9de013833','2024-06-24 19:20:40','2024-06-24 19:20:40','June',24,2024,'521c1037-04c1-4120-8a73-713b742319c9',7,1.5,'Monday','June.24.2024'),
('9d89c612-7b4e-4c9b-a517-d1c5682bdcf3','2024-05-30 17:23:40','2024-05-30 17:23:40','May',30,2024,'521c1037-04c1-4120-8a73-713b742319c9',7,2.5,'Thursday','May.30.2024'),
('9f0d0467-822a-4d33-a3d4-107a3ebefad3','2024-10-20 20:36:39','2024-10-20 20:36:39','October',20,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',2,1.5,'Sunday','October.20.2024'),
('a24e1a9a-9c89-4a71-87a7-d613e1ce5cb4','2024-08-29 17:49:56','2024-08-29 17:49:56','August',29,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',4,1.75,'Thursday','August.29.2024'),
('a7f48b75-4969-438b-a5fc-f4a24ce7a401','2024-10-26 12:35:34','2024-10-26 12:35:34','October',26,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',1,0.5,'Saturday','October.26.2024'),
('ac2ed51c-7d45-4be8-81f7-207720c932c6','2024-08-03 18:16:25','2024-08-03 18:16:25','August',3,2024,'e968804d-fd17-48fd-90a9-be82a84cfbd1',4.75,1.25,'Saturday','August.3.2024'),
('b0399598-ad25-4a7e-a626-2a507fea83ea','2024-05-12 08:45:37','2024-05-12 08:45:37','May',12,2024,'521c1037-04c1-4120-8a73-713b742319c9',1.5,1.5,'Sunday','May.12.2024'),
('b0cfe36e-4dce-4e2e-8c93-9ee9871aefd8','2024-06-30 23:47:01','2024-06-30 23:47:01','June',30,2024,'521c1037-04c1-4120-8a73-713b742319c9',9,2,'Sunday','June.30.2024'),
('b0edbb4a-91bb-4637-91c5-221d96323fe9','2024-05-16 02:37:02','2024-05-16 02:37:02','May',16,2024,'521c1037-04c1-4120-8a73-713b742319c9',3,1,'Thursday','May.16.2024'),
('b2c4ec14-f3e2-456f-ba8b-c5f172e19e8c','2024-04-22 18:17:01','2024-04-22 18:17:01','April',22,2024,'521c1037-04c1-4120-8a73-713b742319c9',4.8,7.2,'Monday','April.22.2024'),
('b3d3ee50-ed25-4d8f-b282-f4f9c0542b69','2024-07-01 22:25:38','2024-07-01 22:25:38','July',1,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,1.25,'Monday','July.1.2024'),
('b6a81d03-83fd-4320-9c7f-0c4e32859228','2024-10-19 02:00:34','2024-10-19 02:00:34','October',19,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',7.33,2.9,'Saturday','October.19.2024'),
('b7a816d2-0b40-4925-8980-f7fcaf6a981b','2024-04-28 02:25:08','2024-04-28 02:25:08','April',28,2024,'521c1037-04c1-4120-8a73-713b742319c9',2,0.5,'6','April.28.2024'),
('b83b8745-23f1-4927-a340-0f3ba4677a3f','2024-06-12 21:15:07','2024-06-12 21:15:07','June',12,2024,'521c1037-04c1-4120-8a73-713b742319c9',4,0.7,'Wednesday','June.12.2024'),
('b8afb25b-8a0d-4c4d-a6d0-fdeac1645b14','2024-10-22 23:48:09','2024-10-22 23:48:09','October',22,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',5.5,2,'Tuesday','October.22.2024'),
('b8ec4fc1-0b92-4b2f-a4eb-f165eb3eaae5','2024-05-13 01:02:02','2024-05-13 01:02:02','May',13,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.75,2,'Monday','May.13.2024'),
('bc879c45-edd3-4262-8b88-5695da1b6d4f','2024-08-15 02:35:22','2024-08-15 02:35:22','August',15,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',5.5,2,'Thursday','August.15.2024'),
('bd122c39-0113-4a97-babd-d3c6a7b9bd31','2024-05-07 11:57:24','2024-05-07 11:57:24','May',7,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,3,'Tuesday','May.7.2024'),
('bd95f528-b846-4573-8f9f-6e2747a29fdc','2024-05-26 01:53:14','2024-05-26 01:53:14','May',26,2024,'521c1037-04c1-4120-8a73-713b742319c9',4,2.5,'Sunday','May.26.2024'),
('bf3823c5-1167-4eea-8a50-debc57e90a0f','2024-08-27 19:24:42','2024-08-27 19:24:42','August',27,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',5,1.35,'Tuesday','August.27.2024'),
('bfdc7c8b-ed92-4bab-8821-1ea7c54bef51','2024-09-04 17:19:32','2024-09-04 17:19:32','September',4,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',3.66,1.5,'Wednesday','September.4.2024'),
('c5464af8-312d-4de7-8c5c-194420137cbb','2024-10-23 22:03:00','2024-10-23 22:03:00','October',23,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',3.5,1,'Wednesday','October.23.2024'),
('c5ff4738-14ef-46d9-8a77-7d6876f87d9d','2024-09-02 21:26:08','2024-09-02 21:26:08','September',2,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',1,5,'Monday','September.2.2024'),
('c7a3ef8b-cb6a-441d-a699-c4143a24f604','2024-08-18 22:35:11','2024-08-18 22:35:11','August',18,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',7.66,3,'Sunday','August.18.2024'),
('cc6ddc0b-1edb-4080-b6ea-6e95226ac2f7','2024-07-11 21:26:55','2024-07-11 21:26:55','July',11,2024,'521c1037-04c1-4120-8a73-713b742319c9',3,1,'Thursday','July.11.2024'),
('cf5a14a3-3d53-44e0-bd97-f0e4602f7941','2024-07-27 05:08:09','2024-07-27 05:08:09','July',27,2024,'8534bb15-9fdf-433f-b444-ab84eac5b913',95,5,'5','July.27.2024'),
('d57338ca-1bc3-4325-8785-d5c204b4f79c','2024-07-02 23:04:01','2024-07-02 23:04:01','July',2,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.5,2,'Tuesday','July.2.2024'),
('da49fce0-f1c4-40db-b328-92d4ab0c333a','2024-09-05 14:57:36','2024-09-05 14:57:36','September',5,2024,'e968804d-fd17-48fd-90a9-be82a84cfbd1',1,0.5,'Thursday','September.5.2024'),
('db300086-93a2-4e51-9e95-b871ad8838b3','2024-06-17 08:01:23','2024-06-17 08:01:23','June',17,2024,'521c1037-04c1-4120-8a73-713b742319c9',4,1.5,'Monday','June.16.24'),
('e3b9eb87-a24e-416d-93aa-5187f153b963','2024-08-09 17:59:40','2024-08-09 17:59:40','August',9,2024,'cf3c64c6-508c-4705-a2ce-5ab5230677f4',6,2,'Friday','August.9.2024'),
('e4238246-50bc-4629-ab7c-3d0f961a53b2','2024-06-30 07:38:18','2024-06-30 07:38:18','June',30,2024,'521c1037-04c1-4120-8a73-713b742319c9',10,2.5,'Sunday','June.30.2024'),
('eb800f45-33f4-4069-9940-74ba28701eef','2024-06-26 16:48:35','2024-06-26 16:48:35','June',26,2024,'521c1037-04c1-4120-8a73-713b742319c9',4.66,0.75,'2','June.26.2024'),
('ebb8d310-fd83-4dc4-8e79-7041456f0722','2024-08-27 19:24:03','2024-08-27 19:24:03','August',27,2024,'e968804d-fd17-48fd-90a9-be82a84cfbd1',1,0.15,'Tuesday','August.27.2024'),
('efc86283-3efa-4b2e-8248-26279c2bd1f1','2024-04-20 22:01:38','2024-04-20 22:01:38','April',20,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.5,4,'Saturday','April.20.2024'),
('efcb0565-41b4-4035-aaa4-f34ded1ca306','2024-06-27 21:27:26','2024-06-27 21:27:26','June',27,2024,'521c1037-04c1-4120-8a73-713b742319c9',7.66,2,'Thursday','June.27.2024'),
('f0c36cc8-8fae-4ac5-92cd-91270a91bcda','2024-05-22 01:57:56','2024-05-22 01:57:56','May',22,2024,'521c1037-04c1-4120-8a73-713b742319c9',4.67,2.5,'Wednesday','May.22.2024'),
('f1d5558e-a9f4-40d5-a1bd-ac45e292fd36','2024-07-03 17:44:04','2024-07-03 17:44:04','July',3,2024,'521c1037-04c1-4120-8a73-713b742319c9',5.75,2.66,'2','July.3.2024'),
('f458c3b6-58e7-473b-8b6f-a46c4eb4c01c','2024-08-06 18:11:21','2024-08-06 18:11:21','August',6,2024,'e968804d-fd17-48fd-90a9-be82a84cfbd1',5,0.75,'Tuesday','August.6.2024'),
('f55449f0-2c9d-4b8c-b88b-a3e250ec4f44','2024-04-30 00:03:11','2024-04-30 00:03:11','April',30,2024,'521c1037-04c1-4120-8a73-713b742319c9',6,2.8,'1','April.30.2024'),
('f6329076-b580-485c-8034-ec0af0502d37','2024-09-18 00:10:32','2024-09-18 00:10:32','September',18,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',4,2,'Wednesday','September.18.2024'),
('f6fcf7ef-0ad1-4c52-8c7e-18aca0112ef0','2024-09-30 20:22:18','2024-09-30 20:22:18','September',30,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',6,2.5,'Monday','September.30.2024'),
('f88ddadb-865b-4a61-b838-81a57dadcb58','2024-10-26 23:45:45','2024-10-26 23:45:45','October',26,2024,'fa53120e-94ae-4c0e-922b-829c978c5e3c',3,0.33,'Saturday','October.26.2024'),
('f9017d7b-c395-4a35-b666-cfacfda50431','2024-05-15 02:24:40','2024-05-15 02:24:40','May',15,2024,'521c1037-04c1-4120-8a73-713b742319c9',5,2,'Wednesday','May.15.2024'),
('fd53fbfc-6cba-4ad8-a0a7-23a13a8a5952','2024-06-04 20:40:24','2024-06-04 20:40:24','June',4,2024,'521c1037-04c1-4120-8a73-713b742319c9',6.5,2.5,'Tuesday','June.4.2024');
/*!40000 ALTER TABLE `daily_log` ENABLE KEYS */;
UNLOCK TABLES;
--
-- Table structure for table `tasks`
--
DROP TABLE IF EXISTS `tasks`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `tasks` (
  `id` varchar(60) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `task_name` varchar(128) NOT NULL,
  `total_time_on_task` float DEFAULT NULL,
  `daily_goal` float NOT NULL,
  `weekly_goal` float NOT NULL,
  `user_id` varchar(60) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `user_id` (`user_id`),
  CONSTRAINT `tasks_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `users` (`id`) ON DELETE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;
--
-- Dumping data for table `tasks`
--
LOCK TABLES `tasks` WRITE;
/*!40000 ALTER TABLE `tasks` DISABLE KEYS */;
INSERT INTO `tasks` VALUES
('1c96b0f1-88db-471e-9ef6-8281ea1a39ee','2024-10-29 16:46:38','2024-10-29 16:46:38','Finish Timecraft',0,8,32,'76af3410-eeba-4379-abe4-ca768b5709af'),
('27302217-0474-40b6-a072-3572c08635cd','2024-10-29 16:46:59','2024-10-29 16:46:59','Build portfolio website',0,6,24,'76af3410-eeba-4379-abe4-ca768b5709af'),
('28bebe7d-2ce0-4d1e-9a26-ff0bb73b0b4f','2024-10-29 00:30:39','2024-10-29 00:30:39','Extracurricular learning ',0,6,36,'b857157a-e199-4098-9718-f6fb94d1ce45'),
('33e1ede4-c82b-4942-9d3c-83609b6b7a0f','2024-10-29 16:41:34','2024-10-29 16:41:34','Task with login',0,5,20,'76af3410-eeba-4379-abe4-ca768b5709af'),
('521c1037-04c1-4120-8a73-713b742319c9','2024-04-16 12:08:36','2024-04-16 12:08:36','Alx',349.98,6,36,'b857157a-e199-4098-9718-f6fb94d1ce45'),
('5aa9462d-1e8f-4738-b790-7f08dd18adca','2024-10-29 16:45:10','2024-10-29 16:45:10','Task with ID 2',0,2,8,'76af3410-eeba-4379-abe4-ca768b5709af'),
('7f62b09c-de00-460e-b492-18a32594c83e','2024-10-29 16:38:48','2024-10-29 16:38:48','Finish data fetching',0,5,20,'76af3410-eeba-4379-abe4-ca768b5709af'),
('82a8fa85-4b39-4512-9732-f14c5053b84c','2024-10-30 15:17:31','2024-10-30 15:17:31','Add tooltips',3,5,30,'b857157a-e199-4098-9718-f6fb94d1ce45'),
('8534bb15-9fdf-433f-b444-ab84eac5b913','2024-07-27 05:07:38','2024-07-27 05:07:38','007',95,100,700,'68f95384-1ad1-4029-989b-c08697c7c3ad'),
('a6978fe9-3ad3-4e45-871a-3ed60be048b8','2024-10-29 16:40:33','2024-10-29 16:40:33','Task with ID',0,5,20,'76af3410-eeba-4379-abe4-ca768b5709af'),
('cf3c64c6-508c-4705-a2ce-5ab5230677f4','2024-08-08 18:33:04','2024-08-08 18:33:04','leetcode',15.8,3,18,'b857157a-e199-4098-9718-f6fb94d1ce45'),
('d016e446-8ce9-4032-9e83-80f0e7a9a957','2024-10-30 15:58:26','2024-10-30 16:04:53','Finish tool tipping',4,5,25,'f64e5dfc-8803-4a8e-9603-4f2b347df607'),
('e968804d-fd17-48fd-90a9-be82a84cfbd1','2024-08-03 18:14:34','2024-08-03 18:14:34','job-search',16.83,3,18,'b857157a-e199-4098-9718-f6fb94d1ce45'),
('f35dad97-dac4-4424-a5a2-15b927099bdc','2024-10-29 16:44:13','2024-10-29 16:44:13','Task with login 2',0,5,20,'76af3410-eeba-4379-abe4-ca768b5709af'),
('fa53120e-94ae-4c0e-922b-829c978c5e3c','2024-08-10 19:29:06','2024-08-10 19:29:06','Projects',177.27,6,36,'b857157a-e199-4098-9718-f6fb94d1ce45');
/*!40000 ALTER TABLE `tasks` ENABLE KEYS */;
UNLOCK TABLES;
--
-- Table structure for table `users`
--
DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `users` (
  `username` varchar(128) NOT NULL,
  `weekly_work_hours_goal` float NOT NULL,
  `number_of_work_days` int(11) NOT NULL,
  `id` varchar(60) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `total_wasted_time` float NOT NULL DEFAULT 0,
  `total_productive_time` float NOT NULL DEFAULT 0,
  `email` varchar(128) DEFAULT NULL,
  `password` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;
--
-- Dumping data for table `users`
--
LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` VALUES
('firstuser1',60,4,'443c634c-7d7c-454c-bf0b-42c2ef53434f','2024-10-28 20:27:39','2024-10-28 20:27:39',0,0,'testuser1@email.com',NULL),
('James Bond',100,7,'68f95384-1ad1-4029-989b-c08697c7c3ad','2024-07-27 05:05:39','2024-07-27 05:05:39',5,95,NULL,NULL),
('seconduser2',60,4,'76af3410-eeba-4379-abe4-ca768b5709af','2024-10-28 21:30:47','2024-10-28 21:30:47',0,0,'testuser2@email.com','$2b$12$2Jhh4O0Spbw/IJxa1LA8L.I5.sm6iEZesjHu8bnGo9C4N.CCP8WUG'),
('thirduser3',60,5,'b40adee5-dfbd-44d3-95b4-ebee70400e5b','2024-10-29 21:32:34','2024-10-29 21:32:34',0,0,NULL,NULL),
('Benoni Esckinder',60,6,'b857157a-e199-4098-9718-f6fb94d1ce45','2024-04-16 12:08:06','2024-04-16 12:08:06',235.8,559.88,NULL,NULL),
('testuser1@email.com',60,5,'f64e5dfc-8803-4a8e-9603-4f2b347df607','2024-10-30 14:41:48','2024-10-30 14:41:48',0,0,NULL,NULL);
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;
/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;
-- Dump completed on 2024-10-30 16:42:00
</file>

<file path="timecraft.py">
#!/usr/bin/python3
""" Console Module """
import cmd
import sys
import os
import uuid
import calendar
from datetime import datetime, date, timedelta
from models.basemodel import BaseModel
from models.__init__ import storage
from models.user import User
from models.task import Task
from models.dailylog import DailyLog
class TcCommand(cmd.Cmd):
    """ Contains all the functionality for the TC console """
    # Display prompt only if in interactive mode
    prompt = '(Tiempo)> ' if sys.stdin.isatty() else ''
    if sys.stdin.isatty():
        # Intro message
        intro = \
            "\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"\
            + "|                                                          |\n"\
            + "|                  Welcome to TimeCraft!                   |\n"\
            + "| You know how it doesn't feel like 24 hours are enough?   |\n"\
            + "| Well, this app is inteded to show exactly where all those|\n"\
            + "| hours are going. It also gives you daily, weekly and     |\n"\
            + "| monthly reports of your time usage.                      |\n"\
            + "| Type help and enter to see a list of commands. Enjoy!    |\n"\
            + "|                                                          |\n"\
            + " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"\
    # Create a dictionary of our classes
    classes = {
            'BaseModel': BaseModel,
            'User': User,
            'Task': Task,
            'Log': DailyLog
        }
    dot_cmds = ['new', 'all_tasks']
    def preloop(self):
        """ Prints prompt before loop if isatty is False """
        if not sys.stdin.isatty():
            print(self.prompt)
    def precmd(self, line):
        """ Reformats commands... IDK how yet """
        _cmd = _cls = ''
        if not ('.' in line and '(' in line and ')' in line):
            return line
        try:
            parsed_line = line[:]
            # isolate the class name
            _cls = pline[:pline.find('.')]
            # isolate and validate command
            _cmd = parsed_line[pline.find('.') + 1:pline.find('(')]
            if _cmd not in TcCommand.dot_cmds:
                raise Exception
        except Exception as mess:
            pass
        finally:
            return linei
    def do_quit(self, command):
        """ Exit timecraft """
        print("Bye!")
        exit()
    def help_quit(self):
        """ Prints the help documentation for quit """
        print(f"Type quit to exit timecraft\n")
    def do_EOF(self, arg):
        """ Handles EOF to exit the program """
        print("\n Bye!")
        exit()
    def help_EOF(self):
        """ Prints the help doc for EOF """
        print(f"You can exit TimeCraft with ctrl^D")
    def emptyline(self):
        """Overrides the emptyline method of CMD"""
        pass
    def do_new(self, args):
        """ Create an object of any class """
        if not args:
            print(f"{self.prompt}Missing Class name :(")
            return
        argv = args.split(" ")
        if argv[0] not in TcCommand.classes:
            print(f"{self.prompt}You can only create a new User, Task or Log."
                  + " Please try again :)")
            return
        # Creates a new User
        if argv[0] == "User":
            user_dict = dict()
            try:
                name = str(input(f"{self.prompt}Hey new user!"
                                 + " What is your name?\n: "))
                weekly_hours_goal = float(
                    input(f"{self.prompt}"
                          + "How many hours would you like to work per week?"
                          + "(Example: 40, 55.5, 20)\n: "))
                work_days = int(
                        input(f"{self.prompt} How many days do you work in a "
                              + "week?\n: "))
            except Exception as e:
                print("Something seems a bit off. "
                      + "Run 'help new' and try again)")
                return
            user_dict["name"] = name
            user_dict["weekly_work_hours_goal"] = weekly_hours_goal
            user_dict["number_of_work_days"] = work_days
            new_user = User(**user_dict)
            storage.new(new_user)
            storage.save()
            # Saves the ID for future use
            storage.user_id = new_user.id
            print("All done. Here is your ID, please remember it."
                  + " You will use it to create tasks and log your "
                  + "activity ;)")
            print(f"Current User: {new_user.name}")
            print(f"User ID: {new_user.id}")
        # Creates a new Task
        elif argv[0] == "Task":
            task_dict = dict()
            try:
                user_id = storage.user_id
                if user_id is None or user_id == "":
                    user_id = str(input("A new task. Cool! But first,"
                                        + " what is your ID?\n: "))
                    storage.user_id = user_id
                user = storage.get_user(user_id)
                if not user:
                    print("There seems to be no user with that ID."
                          + "Please try again")
                    storage.user_id = None
                    return
                print(f"Current User: {user.name}")
                task_name = str(input("Please name your task\n: "))
                total_tot = 0
                daily_goal = float(input("How many hours would you like to "
                                         + "dedicate to this task everyday?\n:"
                                         + " "
                                         ))
                weekly_goal = daily_goal * user.number_of_work_days
            except Exception as e:
                print("Something seems a bit off. "
                      + "Run 'help new' and try again :)")
                return
            task_dict["task_name"] = task_name
            task_dict["daily_goal"] = daily_goal
            task_dict["weekly_goal"] = weekly_goal
            task_dict["user_id"] = user_id
            new_task = Task(**task_dict)
            storage.new(new_task)
            storage.save()
            print("Your new task is saved! Save the task id."
                  + " You will need it to log your activity")
            print(f"Task ID: {new_task.id}")
        # Creates a new log
        elif argv[0] == "Log":
            log_dict = dict()
            try:
                task_id = str(input("What is the task ID?\n: "))
                task = storage.get_task(task_id)
                if not task:
                    print("There seems to be no task with that ID."
                          + " Please try again")
                    return
                user = storage.get_user(task.user_id)
                month = calendar.month_name[datetime.today().month]
                day = datetime.today().day
                year = datetime.today().year
                log_date = f"{month}.{day}.{year}"
                # Day of Week
                Dow = datetime.now().strftime("%A")
                time_on_task = float(input("How much time did you spend on"
                                           + f" {task.task_name} today?\n: "))
                task.total_time_on_task += time_on_task
                user.total_productive_time += time_on_task
                time_wasted = float(input("How much time did you waste"
                                          + " today(It's okay, I won't judge"
                                          + " ;)\n: "))
                user.total_wasted_time += time_wasted
            except Exception as e:
                print("Something seems a bit off. "
                      + "Run 'help new' and try again.")
                return
            log_dict["date"] = log_date
            log_dict["month"] = month
            log_dict["day"] = day
            log_dict["year"] = year
            log_dict["time_on_task"] = time_on_task
            log_dict["time_wasted"] = time_wasted
            log_dict["task_id"] = task_id
            log_dict["day_of_week"] = Dow
            new_log = DailyLog(**log_dict)
            storage.new(new_log)
            storage.save()
            print("Your log has been recorded."
                  + " Make sure to come back tomorrow!")
            print(f"Log ID : {new_log.id}")
    def help_new(self):
        """ Help information for the new method """
        print("Creates a new, task, a new user or a new log")
        print("Usage: new Task | new User | new Log |")
        print("new User: Creates a new User")
        print("new Task: Creates a new Task(needs User ID)")
        print("new Log: Creates a new Log of activities for the day"
              + "(Needs Task ID)")
    def do_all_tasks(self, args):
        """ Gets a list of all tasks associated with a user """
        try:
            user_id = storage.user_id
            if user_id is None or user_id == "":
                user_id = str(input("Can I please see some ID?\n: "))
                storage.user_id = user_id
            # Get all the tasks in storage
            tasks = storage.get_task()
            user_tasks_names = []
            for task in tasks:
                if task.user_id == user_id:
                    user_tasks_names.append(task.task_name)
            if not user_tasks_names:
                print("Looks like this user has no tasks")
                return
            else:
                print("You currently have the following tasks:")
                for task in user_tasks_names:
                    print(f"\t=> {task}")
        except Exception as e:
            print("Please make sure that user id is correct. Thank you!")
            return
    def help_all_tasks(self):
        """ Help information for the all_tasks method """
        print("Get a list of tasks associated with a user")
        print("Usage: Type all tasks and press enter")
        print("     Provide your user ID and get all the tasks of that user.")
    def do_total_time_on_task(self, args):
        """ Gets the total time on a given task """
        try:
            task_id = str(input("Please give me the task ID :)\n: "))
            task = storage.get_task(task_id)
            if not task:
                print("Hmm, couldn't find a task with that ID."
                      + " Please try again")
                return
            print(f"So far, you've spent {task.total_time_on_task} hours"
                  + f" on {task.task_name}")
        except Exception as e:
            print("Something is a bit off. run 'help total_time_on_task' and "
                  + "try again :)")
    def help_total_time_on_task(self):
        """ Help information for the total_time_on_task method """
        print("Gets the total time spent on a task")
        print("Usage: Type 'total_time_on_task' and press enter")
        print("Provide your Task ID")
    def do_delete_task(self, args):
        """ Deletes a task from the list of tasks """
        try:
            task_id = str(input("Please give me the task ID :)\n: "))
            print(f"{self.prompt} Remember that deleting the task deletes all"
                  + "logs associated with the task :)")
            task = storage.get_task(task_id)
            if not task:
                print("Hmm, couldn't find a task with that ID."
                      + " Please try again")
                return
            storage.delete(task)
            storage.save()
            print("Task deleted successfully!")
        except Exception as e:
            print("Something is a bit off. "
                  + "Run 'help delete_task' try again :)")
    def help_delete_task(self):
        """ Help information for delete_task method """
        print("Delete a task. Remember that deleting tasks will also delete"
              + " all logs related to the task")
        print("Usage: type delete_task and press enter")
        print("Enter the task ID for the task you want to delete")
    def do_total_productive_time(self, args):
        try:
            """ Get the total productive hours for a user """
            user_id = storage.user_id
            if user_id == "" or user_id is None:
                user_id = str(input("Can I please see some ID? :)\n: "))
                storage.user_id = user_id
            user = storage.get_user(user_id)
            if not user:
                print("There seems to be no user with that ID")
                storage.user_id = None
                return
            print(f"Current User: {user.name}")
            print(f"So far, you've logged in {user.total_productive_time}"
                  + " hours of solid work. Keep it going!")
        except Exception as e:
            print("Something seems a bit off. Run 'help total_productive_time"
                  + f"' and try again")
    def help_total_productive_time(self):
        """ Help information for total_productive_time """
        print("Find out how much time you've been productive overall")
        print("Usage: Type 'total_productive_time' and press enter")
        print("       Provide your user ID'")
    def do_total_wasted_time(self, args):
        """ Get the total time wasted by a user """
        try:
            user_id = storage.user_id
            if user_id is None or user_id == "":
                user_id = str(input("Can I please see some ID? :)\n: "))
                storage.user_id = user_id
            user = storage.get_user(user_id)
            if not user:
                print("There seems to be no user with that ID")
                storage.user_id = None
                return
            print(f"Current User: {user.name}")
            print(f"So far, you've wasted {user.total_wasted_time} hours."
                  + " Remember, it's about progress not perfection. "
                  + "Keep going!")
        except Exception as e:
            print("Something seems a bit off. Run 'help total_wasted_time'"
                  + " and try again.")
    def help_total_wasted_time(self):
        """ Help informationi for total_wasted_time """
        print("Find how much time a user has wasted so far")
        print("Usage: Type total_wasted_time and press Enter")
        print("       Provide your User ID")
    def do_daily_report(self, args):
        """ Gets a list of all logs for a given day """
        try:
            user_id = storage.user_id
            if user_id is None or user_id == "":
                user_id = str(input("Can I please see some ID? :)\n: "))
                storage.user_id = user_id
            if user_id == "":
                print("Please enter a User ID and try again")
                storage.user_id = None
                return
            date = str(input("What date should we get a report on?\n( Example"
                             + ": today OR February-29-2024 )\n: "))
            date = date.replace('-', '.')
            date = date.replace(':', '.')
            date = date.replace(' ', '.')
            date = date.replace(',', '.')
            if date == "today":
                date = datetime.today().strftime("%B.%-d.%Y")
            elif date == "":
                print("Please enter a proper date and try again.")
                print("Run 'help daily_report' for help")
                return
            logs = storage.get_logs_of_the_day(date)
            if not logs:
                print(f"{self.prompt} There seems to be no logs for today")
                return
        except TypeError as e:
            print(f"{self.prompt} Something seems off. Run 'help daily_report'"
                  + " and try again.")
            return
        total_time_on_task_day = 0
        total_wasted_time_day = 0
        for log in logs:
            task = storage.get_task(log.task_id)
            if task.user_id == user_id:
                total_time_on_task_day += log.time_on_task
                total_wasted_time_day += log.time_wasted
                print(f"{self.prompt} You spent {log.time_on_task} hours on"
                      + f" {task.task_name}")
        print(f"{self.prompt} You spent a total of {total_time_on_task_day} "
              + "hours working")
        print()
        print(f"{self.prompt} You wasted a total of {total_wasted_time_day} "
              + "hours today")
        print(f"{self.prompt} Tomorrow is always another day. Salute!")
    def help_daily_report(self):
        """ Handles ducumentation for the method daily_report """
        print("daily_report: Gets a report of your daily time on task and "
              + "time wasted")
        print("Usage: type daily_report and press enter")
        print("Provide your user ID and the day you want to get logs for")
    def do_weekly_report(self, args):
        """ Gets a weekly report of time_on_task and time_wasted """
        try:
            user_id = storage.user_id
            if user_id is None or user_id == "":
                user_id = str(input("Can I please see some ID? :)\n : "))
                storage.user_id = user_id
            user = storage.get_user(user_id)
            if not user:
                print("There seems to be no user with that ID."
                      + f" Please try again!")
                storage.user_id = None
                return
            print(f"Current User: {user.name}")
            date = str(input("Please choose from these options\n"
                             + "this_week   last_week    custom\n: "))
            def this_week(date):
                """ Gets a weekly report from Monday to Sunday based on a
                    given date. """
                weekday_offset = date.weekday()
                start_date = date - timedelta(days=weekday_offset)
                print(f"Start Date: {start_date.strftime('%B.%-d.%Y')}")
                # 7 days of the week
                end_date = start_date + timedelta(days=6)
                print(f"End Date: {end_date.strftime('%B.%-d.%Y')}")
                total_time_on_task_week = 0
                total_wasted_time_week = 0
                day = start_date
                while day < end_date:
                    log_id = day.strftime("%B.%-d.%Y")
                    logs = storage.get_logs_of_the_day(log_id)
                    for log in logs:
                        task = storage.get_task(log.task_id)
                        if task.user_id == user_id:
                            total_time_on_task_week += log.time_on_task
                            total_wasted_time_week += log.time_wasted
                    day += timedelta(days=1)
                if total_time_on_task_week == 0 and\
                        total_wasted_time_week == 0:
                    print("There are no logs for this week.")
                    return
                print(f"{self.prompt} This week you spent "
                      + f"{total_time_on_task_week}"
                      + " hours wroking.\nWay to move forward!")
                print(f"{self.prompt} You wasted a total of "
                      + f"{total_wasted_time_week} "
                      + "hours.\nYou can't be perfect. But you can be better."
                      + " See you next week! :))")
            today = datetime.today()
            if date == "this_week":
                this_week(today)
            elif date == "last_week":
                print(today - timedelta(days=7))
                this_week(today - timedelta(days=7))
            elif date == "custom":
                custom_date = str(input("Please enter a starting date\n"
                                        + "(Example: February-29-2024)\n: "))
                custom_date = custom_date.replace('-', '.')
                custom_date = custom_date.replace(' ', '.')
                custom_date = custom_date.replace(',', '.')
                custom_date = datetime.strptime(custom_date, "%B.%d.%Y")
                this_week(custom_date)
            else:
                print(f"{self.prompt} Please choose between only the "
                      + "3 options. Thank You!")
                return
        except ValueError:
            print("Please make sure you enter a valid date when using the"
                  + " 'custom' option")
        except Exception as e:
            print(f"{self.prompt} Something seems a bit off."
                  + " Run 'help weekly_report' and try again")
    def help_weekly_report(self):
        """ Handles ducumentation for the method weekly_report """
        print(f"weekly_report: Gets a report of your weekly time on task"
              + " and time wasted")
        print(f"Usage: Type 'weekly_report' and press enter")
        print("Provide your User ID and choose between this_week, "
              + "last_week or custom(Choose a date and get a report "
              + "for that week)")
    def do_monthly_report(self, args):
        """ Get the total time on task and total wasted time for the month """
        try:
            user_id = storage.user_id
            if user_id is None or user_id == "":
                user_id = str(input("Can I please see some ID? :)\n : "))
                storage.user_id = user_id
            user = storage.get_user(user_id)
            if not user:
                print("There seems to be no user with that ID."
                      + " Please try again!")
                stprage.user_id = None
                return
            print(f"Current User: {user.name}")
            month = str(input("What month would you like to get a report for?"
                              + "\n (Example: February) : "))
            # Total time on task this month
            ttot_month = 0
            # Total wasted time this month
            twt_month = 0
            logs = storage.get_logs_of_the_day()
            logs_of_the_month = []
            for log in logs:
                if log.month == month:
                    logs_of_the_month.append(log)
            if not logs_of_the_month:
                print(f"{self.prompt} Hmm... it looks like there are no logs"
                      + " for that month. Try Another one")
                return
            for log in logs_of_the_month:
                task = storage.get_task(log.task_id)
                if task.user_id == user_id:
                    ttot_month += log.time_on_task
                    twt_month += log.time_wasted
            print(f"{self.prompt} In the month of {month}, you have spent"
                  + f" {ttot_month} hours working. Way to go!")
            print(f"{self.prompt} You have wasted {twt_month} hours this"
                  + f" month.")
            print(f"{self.prompt} You did good. Here is to doing better next"
                  + " month!")
            print()
        except Exception as e:
            print(f"{self.prompt} Something seems to be a bit off."
                  + " Run 'help monthly_report' and try agian :)")
    def help_monthly_report(self):
        """ Handles documentation for the method monthly_report """
        print("monthly_report: Gets report of time on task and time wasted\n"
              + "for a specified month")
        print("usage: Type 'monthly_report' and press enter")
        print("Provide your User ID and the month you want to "
              + "get a report for")
    def do_switch_user(self, args):
        ''' Switches the user_id we are operating with '''
        user_id = str(input("Can I please have the user ID?\n: "))
        user = storage.get_user(user_id)
        if not user:
            print(f"{self.prompt} There seems to be no user with that ID"
                  + ". Please try again")
            return
        storage.user_id = user_id
        print(f"Switched to user {user.name}")
    def help_switch_user(self):
        ''' Documentation for the method switch_user '''
        print("switch_user: Switches from one user to another. Provided"
              + " that it exists")
        print("usage: Type 'switch_user' and press enter")
        print("Provide the user ID of the User you want to switch to")
if __name__ == "__main__":
    TcCommand().cmdloop()
</file>

</files>
